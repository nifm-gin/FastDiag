{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5cae00-a46a-433b-b0a7-7110593f5663",
   "metadata": {},
   "source": [
    "### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb4cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.warn = warn\n",
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore::UserWarning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0336203-bd6a-4327-9b9a-477037a13a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from utility.utility import false_neg_scorer, false_pos_scorer\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "from get_outcomes import get_mortality_6m\n",
    "import warnings\n",
    "#import shap\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14779e12-7eae-4b43-9729-b973d9f9c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba999991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name  mortality\n",
      "0  P0000          0\n",
      "1  P0001          0\n",
      "2  P0002          0\n",
      "3  P0003          0\n",
      "4  P0004          0\n",
      "Outcome events : 33\n"
     ]
    }
   ],
   "source": [
    "y = get_mortality_6m()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c0ff40-f90c-4b48-ab18-3816a9d6785d",
   "metadata": {},
   "source": [
    "### Preprocessing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e7956ed-1c05-45e4-852e-cd49b1d584ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>supratentorial_IPH</th>\n",
       "      <th>supratentorial_SAH</th>\n",
       "      <th>supratentorial_Petechiae</th>\n",
       "      <th>supratentorial_Edema</th>\n",
       "      <th>infratentorial_IPH</th>\n",
       "      <th>infratentorial_SAH</th>\n",
       "      <th>infratentorial_Petechiae</th>\n",
       "      <th>infratentorial_Edema</th>\n",
       "      <th>brainstem_IPH</th>\n",
       "      <th>...</th>\n",
       "      <th>pression_arterielle_diastolique_PAD_arrivee_du_smur</th>\n",
       "      <th>score_glasgow_initial</th>\n",
       "      <th>score_glasgow_moteur_initial</th>\n",
       "      <th>anomalie_pupillaire_prehospitalier</th>\n",
       "      <th>frequence_cardiaque_FC_arrivee_du_smur</th>\n",
       "      <th>arret_cardio_respiratoire_massage</th>\n",
       "      <th>penetrant_objet</th>\n",
       "      <th>ischemie_du_membre</th>\n",
       "      <th>hemorragie_externe</th>\n",
       "      <th>amputation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0001</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0003</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0004</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0005</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  supratentorial_IPH  supratentorial_SAH  supratentorial_Petechiae  \\\n",
       "0  P0001                   0                 342                         0   \n",
       "1  P0002                   0                   0                         0   \n",
       "2  P0003                   0                 101                         0   \n",
       "3  P0004                   0                 328                         0   \n",
       "4  P0005                   0                   9                         0   \n",
       "\n",
       "   supratentorial_Edema  infratentorial_IPH  infratentorial_SAH  \\\n",
       "0                     0                   0                  15   \n",
       "1                     0                   0                   0   \n",
       "2                     0                   0                   0   \n",
       "3                     0                   0                   0   \n",
       "4                    15                   0                   0   \n",
       "\n",
       "   infratentorial_Petechiae  infratentorial_Edema  brainstem_IPH  ...  \\\n",
       "0                         0                     0              0  ...   \n",
       "1                         0                     0              0  ...   \n",
       "2                         0                     0              0  ...   \n",
       "3                         0                     0              0  ...   \n",
       "4                         0                     0              0  ...   \n",
       "\n",
       "   pression_arterielle_diastolique_PAD_arrivee_du_smur  score_glasgow_initial  \\\n",
       "0                                               49.0                     15.0   \n",
       "1                                               60.0                     15.0   \n",
       "2                                               64.0                     14.0   \n",
       "3                                               71.0                     15.0   \n",
       "4                                               79.0                      NaN   \n",
       "\n",
       "   score_glasgow_moteur_initial  anomalie_pupillaire_prehospitalier  \\\n",
       "0                           6.0                                 0.0   \n",
       "1                           6.0                                 0.0   \n",
       "2                           6.0                                 0.0   \n",
       "3                           6.0                                 0.0   \n",
       "4                           NaN                                 0.0   \n",
       "\n",
       "   frequence_cardiaque_FC_arrivee_du_smur  arret_cardio_respiratoire_massage  \\\n",
       "0                                    56.0                                0.0   \n",
       "1                                   100.0                                0.0   \n",
       "2                                   120.0                                0.0   \n",
       "3                                   107.0                                0.0   \n",
       "4                                    83.0                                0.0   \n",
       "\n",
       "   penetrant_objet  ischemie_du_membre  hemorragie_externe  amputation  \n",
       "0              0.0                 0.0                 0.0         0.0  \n",
       "1              0.0                 0.0                 0.0         0.0  \n",
       "2              0.0                 0.0                 0.0         0.0  \n",
       "3              0.0                 0.0                 0.0         0.0  \n",
       "4              0.0                 0.0                 0.0         0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_volumes_clinical = pd.read_csv(DATA_DIRECTORY+\"segmentation_data_anonymized.csv\", usecols=range(1,31))\n",
    "X_volumes_clinical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24face50-fac0-4b63-bb9f-3b99fa422428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>hemocue_initial</th>\n",
       "      <th>fracas_du_bassin</th>\n",
       "      <th>catecholamines</th>\n",
       "      <th>pression_arterielle_systolique_PAS_arrivee_du_smur</th>\n",
       "      <th>pression_arterielle_diastolique_PAD_arrivee_du_smur</th>\n",
       "      <th>score_glasgow_initial</th>\n",
       "      <th>score_glasgow_moteur_initial</th>\n",
       "      <th>anomalie_pupillaire_prehospitalier</th>\n",
       "      <th>frequence_cardiaque_FC_arrivee_du_smur</th>\n",
       "      <th>arret_cardio_respiratoire_massage</th>\n",
       "      <th>penetrant_objet</th>\n",
       "      <th>ischemie_du_membre</th>\n",
       "      <th>hemorragie_externe</th>\n",
       "      <th>amputation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0001</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0002</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0003</td>\n",
       "      <td>42.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0004</td>\n",
       "      <td>34.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0005</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name   age  hemocue_initial  fracas_du_bassin  catecholamines  \\\n",
       "0  P0001  52.0              NaN               0.0             0.0   \n",
       "1  P0002  23.0              NaN               0.0             0.0   \n",
       "2  P0003  42.0             13.1               0.0             0.0   \n",
       "3  P0004  34.0             15.8               0.0             0.0   \n",
       "4  P0005  22.0              NaN               0.0             0.0   \n",
       "\n",
       "   pression_arterielle_systolique_PAS_arrivee_du_smur  \\\n",
       "0                                               87.0    \n",
       "1                                              100.0    \n",
       "2                                              101.0    \n",
       "3                                              110.0    \n",
       "4                                              114.0    \n",
       "\n",
       "   pression_arterielle_diastolique_PAD_arrivee_du_smur  score_glasgow_initial  \\\n",
       "0                                               49.0                     15.0   \n",
       "1                                               60.0                     15.0   \n",
       "2                                               64.0                     14.0   \n",
       "3                                               71.0                     15.0   \n",
       "4                                               79.0                      NaN   \n",
       "\n",
       "   score_glasgow_moteur_initial  anomalie_pupillaire_prehospitalier  \\\n",
       "0                           6.0                                 0.0   \n",
       "1                           6.0                                 0.0   \n",
       "2                           6.0                                 0.0   \n",
       "3                           6.0                                 0.0   \n",
       "4                           NaN                                 0.0   \n",
       "\n",
       "   frequence_cardiaque_FC_arrivee_du_smur  arret_cardio_respiratoire_massage  \\\n",
       "0                                    56.0                                0.0   \n",
       "1                                   100.0                                0.0   \n",
       "2                                   120.0                                0.0   \n",
       "3                                   107.0                                0.0   \n",
       "4                                    83.0                                0.0   \n",
       "\n",
       "   penetrant_objet  ischemie_du_membre  hemorragie_externe  amputation  \n",
       "0              0.0                 0.0                 0.0         0.0  \n",
       "1              0.0                 0.0                 0.0         0.0  \n",
       "2              0.0                 0.0                 0.0         0.0  \n",
       "3              0.0                 0.0                 0.0         0.0  \n",
       "4              0.0                 0.0                 0.0         0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_load = list(range(16, 31)) + [1]\n",
    "\n",
    "X_clinical_only = pd.read_csv(DATA_DIRECTORY+\"segmentation_data_anonymized.csv\", usecols=columns_to_load)\n",
    "X_clinical_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9829293f-4f10-4749-bd2d-6749e83c1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify indexes where 'mortality' is NaN in y\n",
    "nan_indexes = y.loc[pd.isna(y[\"mortality\"]), :].index\n",
    "print(f\"Indexes with NaN in 'mortality': {nan_indexes}\")\n",
    "\n",
    "# Drop rows with NaN in y\n",
    "y = y.drop(index=nan_indexes)\n",
    "\n",
    "# Ensure 'name' is the index or used for alignment\n",
    "X_volumes_clinical = X_volumes_clinical[~X_volumes_clinical['name'].isin(y.loc[nan_indexes, 'name'])]\n",
    "\n",
    "# Verify the shapes after cleaning\n",
    "print(f\"Shape of y after cleaning: {y.shape}\")\n",
    "print(f\"Shape of X_volumes_clinical after cleaning: {X_volumes_clinical.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c5d98-ede1-45dc-8aa2-e5addd948d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifiez les valeurs uniques de 'name' dans y\n",
    "print(\"Unique 'name' values in y:\", y['name'].nunique())\n",
    "\n",
    "# Vérifiez les valeurs uniques de 'name' dans X_volumes_clinical_with_outcome\n",
    "print(\"Unique 'name' values in X_volumes_clinical:\", X_volumes_clinical['name'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1063a3-b21f-4c73-942d-ababf0c47770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noms dans y mais pas dans X_volumes_clinical\n",
    "missing_in_X = set(y['name']) - set(X_volumes_clinical['name'])\n",
    "print(f\"Names in y but not in X_volumes_clinical: {missing_in_X}\")\n",
    "\n",
    "# Noms dans X_volumes_clinical mais pas dans y\n",
    "missing_in_y = set(X_volumes_clinical['name']) - set(y['name'])\n",
    "print(f\"Names in X_volumes_clinical but not in y: {missing_in_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb1d58-c0a7-438f-82be-f64e1794df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver les noms communs\n",
    "common_names = set(y['name']).intersection(set(X_volumes_clinical['name']))\n",
    "\n",
    "# Filtrer y et X_volumes_clinical_with_outcome pour ne garder que les noms communs\n",
    "y = y[y['name'].isin(common_names)]\n",
    "X_volumes_clinical = X_volumes_clinical[X_volumes_clinical['name'].isin(common_names)]\n",
    "\n",
    "# Vérifiez les dimensions après nettoyage\n",
    "print(f\"Shape of y after alignment: {y.shape}\")\n",
    "print(f\"Shape of X_volumes_clinical_with_outcome after alignment: {X_volumes_clinical.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ff8e56-856d-41da-9685-91de3a139fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in 'name' in y\n",
    "print(\"Number of duplicate names in y:\", y['name'].duplicated().sum())\n",
    "\n",
    "# Check for duplicates in 'name' in X_volumes_clinical_with_outcome\n",
    "print(\"Number of duplicate names in X_volumes_clinical:\", X_volumes_clinical['name'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a162eebf-0d5d-4fdc-9d65-bca6a9205245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates from both DataFrames\n",
    "y = y.drop_duplicates(subset=['name'])\n",
    "X_volumes_clinical = X_volumes_clinical.drop_duplicates(subset=['name'])\n",
    "\n",
    "# Verify the shapes again\n",
    "print(f\"Shape of y after removing duplicates: {y.shape}\")\n",
    "print(f\"Shape of X_volumes_clinical after removing duplicates: {X_volumes_clinical.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d4c78-3a64-4210-8544-5ef7dfb7643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_volumes_clinical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b1b63-86f3-4377-a00f-5030d037b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'name' values are the same in both DataFrames\n",
    "common_names = set(y['name']) == set(X_volumes_clinical['name'])\n",
    "print(f\"Are 'name' values aligned between y and X_volumes_clinical? {common_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8953658-c6f7-4d3d-8f4e-f031e01bd9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trier y et X par la colonne 'name'\n",
    "y = y.sort_values(by='name').reset_index(drop=True)\n",
    "X_volumes_clinical = X_volumes_clinical.sort_values(by='name').reset_index(drop=True)\n",
    "\n",
    "# Vérifier si les noms sont alignés\n",
    "print((y['name'].values == X_volumes_clinical['name'].values).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d1ca75-c88f-40ef-ace8-d0746678517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'name' column from X_volumes_clinical_with_outcome\n",
    "X_features = X_volumes_clinical.drop(columns=['name'])\n",
    "\n",
    "# imputation with median \n",
    "X_features_imputed = X_features.fillna(X_features.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6515ad1-0dc1-4382-8d60-bcd121e25902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'name' column from y (if it exists)\n",
    "y_outcome = y.drop(columns=['name'])\n",
    "\n",
    "# Ensure y_outcome is a 1D array\n",
    "y_outcome = y_outcome.values.ravel()  # Convert to 1D if using pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948613f6-461a-446a-bfa0-8f704738c35c",
   "metadata": {},
   "source": [
    "### Gradient boosting with traumatrix model + segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ddede",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4719e-1d7e-4c18-9604-d76a947b44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5\n",
    "N_REPEATS = 3\n",
    "nb_total_samples = len(y_outcome)\n",
    "\n",
    "pipeline_smote_under = Pipeline(steps=[('over', SMOTE()), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "#pipeline_smote_under = Pipeline(steps=[('over', SMOTENC(categorical_features=[\"fracas_du_bassin\", \"amputation\"])), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "\n",
    "\n",
    "inner_cv = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=5, random_state=1)\n",
    "\n",
    "p_grid = {\"model__learning_rate\": [0.01, 0.05, 0.08, 0.1, 0.2, 0.3, 0.5, 1], \"over__sampling_strategy\": [0.1, 0.2, 0.3], \"over__k_neighbors\":[3,5,8], \"under__sampling_strategy\":[0.3, 0.5, 0.7]}\n",
    "clf = GridSearchCV(estimator=pipeline_smote_under, param_grid=p_grid, scoring={'F2':ftwo_scorer}, refit='F2', cv=inner_cv)\n",
    "\n",
    "outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "nested_scores_smote_undersampling = cross_validate(clf, X_features_imputed, y_outcome, \n",
    "                                                   scoring={'F2':ftwo_scorer, 'ROC_AUC':'roc_auc', 'Recall':'recall_macro', 'F1':'f1', 'Brier':\"neg_brier_score\", 'False_neg_scorer':false_neg_scorer, 'False_pos_scorer':false_pos_scorer}, \n",
    "                                                   cv=outer_cv, n_jobs=-1, return_estimator=True, return_indices=True)\n",
    "\n",
    "print(\"HistGradientBoostingClassifier with hyperparameter gridsearch\")\n",
    "\n",
    "roc_auc_metric = np.mean(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "roc_auc_metric_std = np.std(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "print(f'AUC (max): {np.round(roc_auc_metric, 2)} +- {np.round(roc_auc_metric_std, 2)}')\n",
    "\n",
    "f1_score = np.mean(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "f1_score_std = np.std(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "print(f'F1 Score (max): {np.round(f1_score, 2)} +- {np.round(f1_score_std, 2)}')\n",
    "\n",
    "f2_score = np.mean(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "f2_score_std = np.std(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "print(f'F2 Score (max): {np.round(f2_score, 2)} +- {np.round(f2_score_std, 2)}')\n",
    "\n",
    "brier_score = -np.mean(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "brier_score_std = -np.std(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "print(f'Brier Score (min): {np.round(brier_score, 2)} +- {np.round(brier_score_std, 2)}')\n",
    "\n",
    "# test_False_neg_scorer returns the number of test false negatives -> to get a % we need to divide by the number of test samples*100\n",
    "false_neg_score = np.mean(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "false_neg_score_std = np.std(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "print(f'False negative: {int(np.round(false_neg_score, 0))}% +- {int(np.round(false_neg_score_std, 0))}')\n",
    "\n",
    "false_pos_score = np.mean(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "false_pos_score_std = np.std(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "print(f'False positive: {int(np.round(false_pos_score, 0))}% +- {int(np.round(false_pos_score_std, 0))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b665e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimator in nested_scores_smote_undersampling['estimator']:\n",
    "    print(estimator.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e25fb62",
   "metadata": {},
   "source": [
    "#### Get individual test set samples prediction vs ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d2e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(nested_scores_smote_undersampling[\"indices\"][\"test\"])):\n",
    "    if 469 in nested_scores_smote_undersampling[\"indices\"][\"test\"][i]:\n",
    "        print(f'fold={i}')\n",
    "    #print(f\"fold={i}\")\n",
    "    #print(nested_scores_smote_undersampling[\"indices\"][\"test\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e37a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 11\n",
    "\n",
    "y_true_train = np.asarray(y_outcome)[nested_scores_smote_undersampling[\"indices\"][\"train\"][fold]]\n",
    "y_true_test = np.asarray(y_outcome)[nested_scores_smote_undersampling[\"indices\"][\"test\"][fold]]\n",
    "\n",
    "fitted = nested_scores_smote_undersampling[\"estimator\"][0].fit(X_features_imputed.loc[nested_scores_smote_undersampling[\"indices\"][\"train\"][fold]], y_true_train) #-#=#\n",
    "\n",
    "pred_test = fitted.predict(X_features_imputed.loc[nested_scores_smote_undersampling[\"indices\"][\"test\"][fold]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8accaa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"y_pred: {pred_test}\")\n",
    "print(f\"y_true: {y_true_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf857b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find true positive\n",
    "\n",
    "true_positive_index = -1\n",
    "\n",
    "for i in range(len(y_true_test)):\n",
    "    if y_true_test[i] == 1 and pred_test[i] == 1:\n",
    "        true_positive_index = nested_scores_smote_undersampling[\"indices\"][\"test\"][fold][i]\n",
    "        print(f\"true positive at index {true_positive_index}, i={i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222550e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find true negative\n",
    "\n",
    "true_negative_index = -1\n",
    "\n",
    "for i in range(len(y_true_test)):\n",
    "    if y_true_test[i] == 0 and pred_test[i] == 0:\n",
    "        true_negative_index = nested_scores_smote_undersampling[\"indices\"][\"test\"][fold][i]\n",
    "        print(f\"true negative at index {true_negative_index}, i={i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8005551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find false negative\n",
    "\n",
    "false_negative_index = -1\n",
    "\n",
    "for i in range(len(y_true_test)):\n",
    "    if y_true_test[i] == 1 and pred_test[i] == 0:\n",
    "        false_negative_index = nested_scores_smote_undersampling[\"indices\"][\"test\"][fold][i]\n",
    "        print(f\"false negative at index {false_negative_index}, i={i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac840299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find false positive\n",
    "\n",
    "false_positive_index = -1\n",
    "\n",
    "for i in range(len(y_true_test)):\n",
    "    if y_true_test[i] == 0 and pred_test[i] == 1:\n",
    "        false_positive_index = nested_scores_smote_undersampling[\"indices\"][\"test\"][fold][i]\n",
    "        print(f\"false positive at index {false_positive_index}, i={i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8203c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data for this individual\n",
    "print(X_volumes_clinical.loc[469])\n",
    "#X_volumes_clinical.loc[329].to_csv(\"patient_inference_results/P0010.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bced28f",
   "metadata": {},
   "source": [
    "#### SHAP explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e5270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitted.best_estimator_[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac1f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(fitted.best_estimator_[\"model\"]) \n",
    "shap_values2 = explainer(X_features_imputed.loc[nested_scores_smote_undersampling[\"indices\"][\"test\"][fold]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b446dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values2[94])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30e0e66",
   "metadata": {},
   "source": [
    "#### Confidence intervals with test set bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abba49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_list = []\n",
    "\n",
    "for estimator in nested_scores_smote_undersampling[\"estimator\"]:\n",
    "    best_params_list.append(frozenset(estimator.best_params_.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab380b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Convert dict to a hashable tuple and count occurrences\n",
    "most_common_params = Counter(best_params_list).most_common(1)[0][0]\n",
    "final_params = dict(most_common_params)  # Convert back to dict\n",
    "\n",
    "\n",
    "print(\"Final chosen hyperparameters:\", final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf462f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('over', SMOTE(k_neighbors=3, sampling_strategy=0.3)), ('under', RandomUnderSampler(sampling_strategy=0.7)), ('model', HistGradientBoostingClassifier(learning_rate=0.2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b1ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(pipeline, X_features_imputed, y_outcome, cv=20, method='predict_proba')[:,1]\n",
    "\n",
    "y_pred_binary = [1 if i>=0.5 else 0 for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b443e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, confusion_matrix, roc_auc_score, f1_score, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b68389",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=12345)\n",
    "idx = np.arange(len(y_outcome))\n",
    "\n",
    "y_pred = np.asarray(y_pred)\n",
    "y_pred_binary = np.asarray(y_pred_binary)\n",
    "y = np.asarray(y_outcome)\n",
    "X_dropped = np.asarray(X_features_imputed)\n",
    "\n",
    "test_roc_auc = []\n",
    "test_f1 = []\n",
    "test_ftwos = []\n",
    "test_brier = []\n",
    "test_false_neg = []\n",
    "test_false_pos = []\n",
    "\n",
    "for i in range(200): # bootstrap with 200 rounds: random sampling with replacement of the predictions\n",
    "\n",
    "    pred_idx = rng.choice(idx, size=len(idx), replace=True)\n",
    "    \n",
    "    roc_auc_test_boot = roc_auc_score(y_score=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    f1_test_boot = f1_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx])\n",
    "    f2_test_boot = fbeta_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx], beta=2)\n",
    "    brier_test_boot = brier_score_loss(y_proba=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    false_neg_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[1,0]\n",
    "    false_pos_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[0,1]\n",
    "    \n",
    "    test_roc_auc.append(roc_auc_test_boot)\n",
    "    test_f1.append(f1_test_boot)\n",
    "    test_ftwos.append(f2_test_boot)\n",
    "    test_brier.append(brier_test_boot)\n",
    "    test_false_neg.append(false_neg_test_boot/len(idx)*100)\n",
    "    test_false_pos.append(false_pos_test_boot/len(idx)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde39664",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification performance\\n\")\n",
    "\n",
    "bootstrap_roc_auc_test_mean = np.mean(test_roc_auc)\n",
    "ci_lower = np.percentile(test_roc_auc, 2.5)     # 2.5 percentile (alpha=0.025)\n",
    "ci_upper = np.percentile(test_roc_auc, 97.5)\n",
    "print(f\"ROC AUC:         {bootstrap_roc_auc_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f1_test_mean = np.mean(test_f1)\n",
    "ci_lower = np.percentile(test_f1, 2.5)\n",
    "ci_upper = np.percentile(test_f1, 97.5)\n",
    "print(f\"F1:              {bootstrap_f1_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f2_test_mean = np.mean(test_ftwos)\n",
    "ci_lower = np.percentile(test_ftwos, 2.5)\n",
    "ci_upper = np.percentile(test_ftwos, 97.5)\n",
    "print(f\"F2:              {bootstrap_f2_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_brier_test_mean = np.mean(test_brier)\n",
    "ci_lower = np.percentile(test_brier, 2.5)\n",
    "ci_upper = np.percentile(test_brier, 97.5)\n",
    "print(f\"Brier loss:      {bootstrap_brier_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_neg_test_mean = np.mean(test_false_neg)\n",
    "ci_lower = np.percentile(test_false_neg, 2.5)\n",
    "ci_upper = np.percentile(test_false_neg, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_neg_test_mean:.2f}%;  95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_pos_test_mean = np.mean(test_false_pos)\n",
    "ci_lower = np.percentile(test_false_pos, 2.5)\n",
    "ci_upper = np.percentile(test_false_pos, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_pos_test_mean:.2f}%; 95% CI {ci_lower:.2f}-{ci_upper:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61558cd4-b568-472e-9e2e-6a994a50978e",
   "metadata": {},
   "source": [
    "### Gradient boosting with segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa280aa5-2b82-4300-b55e-431e541d9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run --> prepocessing outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f79fc-2efa-47b0-872c-efed5af7647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(DATA_DIRECTORY+\"segmentation_data_anonymized.csv\", usecols=range(1,16))\n",
    "X.head()\n",
    "\n",
    "y = get_mortality_6m()\n",
    "\n",
    "# Identify indexes where 'mortality' is NaN in y\n",
    "try:\n",
    "    nan_indexes = y.loc[pd.isna(y[\"mortality\"]), :].index\n",
    "except:\n",
    "    nan_indexes=[]\n",
    "print(f\"Indexes with NaN in 'mortality': {nan_indexes}\")\n",
    "\n",
    "# Drop rows with NaN in y\n",
    "y = y.drop(index=nan_indexes)\n",
    "\n",
    "# Ensure 'name' is the index or used for alignment\n",
    "X = X[~X['name'].isin(y.loc[nan_indexes, 'name'])]\n",
    "\n",
    "# Verify the shapes after cleaning\n",
    "print(f\"Shape of y after cleaning: {y.shape}\")\n",
    "print(f\"Shape of X after cleaning: {X.shape}\")\n",
    "\n",
    "# Vérifiez les valeurs uniques de 'name' dans y\n",
    "print(\"Unique 'name' values in y:\", y['name'].nunique())\n",
    "\n",
    "# Vérifiez les valeurs uniques de 'name' dans X\n",
    "print(\"Unique 'name' values in X:\", X['name'].nunique())\n",
    "\n",
    "# Noms dans y mais pas dans X\n",
    "missing_in_X = set(y['name']) - set(X['name'])\n",
    "print(f\"Names in y but not in X: {missing_in_X}\")\n",
    "\n",
    "# Noms dans X mais pas dans y\n",
    "missing_in_y = set(X['name']) - set(y['name'])\n",
    "print(f\"Names in X but not in y: {missing_in_y}\")\n",
    "\n",
    "# Trouver les noms communs\n",
    "common_names = set(y['name']).intersection(set(X['name']))\n",
    "\n",
    "# Filtrer y et X pour ne garder que les noms communs\n",
    "y = y[y['name'].isin(common_names)]\n",
    "X = X[X['name'].isin(common_names)]\n",
    "\n",
    "# Vérifiez les dimensions après nettoyage\n",
    "print(f\"Shape of y after alignment: {y.shape}\")\n",
    "print(f\"Shape of X after alignment: {X.shape}\")\n",
    "\n",
    "# Check for duplicates in 'name' in y\n",
    "print(\"Number of duplicate names in y:\", y['name'].duplicated().sum())\n",
    "\n",
    "# Check for duplicates in 'name' in X\n",
    "print(\"Number of duplicate names in X:\", X['name'].duplicated().sum())\n",
    "\n",
    "# Remove duplicates from both DataFrames\n",
    "y = y.drop_duplicates(subset=['name'])\n",
    "X = X.drop_duplicates(subset=['name'])\n",
    "\n",
    "# Verify the shapes again\n",
    "print(f\"Shape of y after removing duplicates: {y.shape}\")\n",
    "print(f\"Shape of X after removing duplicates: {X.shape}\")\n",
    "\n",
    "# Check if 'name' values are the same in both DataFrames\n",
    "common_names = set(y['name']) == set(X['name'])\n",
    "print(f\"Are 'name' values aligned between y and X {common_names}\")\n",
    "\n",
    "# Trier y et X par la colonne 'name'\n",
    "y = y.sort_values(by='name').reset_index(drop=True)\n",
    "X = X.sort_values(by='name').reset_index(drop=True)\n",
    "\n",
    "# Vérifier si les noms sont alignés\n",
    "print((y['name'].values == X['name'].values).all())\n",
    "\n",
    "# Drop the 'name' column from X\n",
    "X_features = X.drop(columns=['name'])\n",
    "\n",
    "# imputation with median \n",
    "X_features_imputed = X_features.fillna(X_features.median())\n",
    "\n",
    "# Drop the 'name' column from y (if it exists)\n",
    "y_outcome = y.drop(columns=['name'])\n",
    "\n",
    "# Ensure y_outcome is a 1D array\n",
    "y_outcome = y_outcome.values.ravel()  # Convert to 1D if using pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30e794-21db-4faf-828d-383fef042336",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ones = np.sum(y_outcome == 1)  # True values are treated as 1 in numpy\n",
    "print(f\"Number of y = 1 in y_outcome: {num_ones}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c90a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0064cad9-f62f-4af1-9225-b657e5b7bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5\n",
    "N_REPEATS = 3\n",
    "nb_total_samples = len(y_outcome)\n",
    "\n",
    "pipeline_smote_under = Pipeline(steps=[('over', SMOTE()), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "#pipeline_smote_under = Pipeline(steps=[('over', SMOTENC(categorical_features=[\"fracas_du_bassin\", \"amputation\"])), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "\n",
    "\n",
    "inner_cv = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=5, random_state=1)\n",
    "\n",
    "p_grid = {\"model__learning_rate\": [0.01, 0.05, 0.08, 0.1, 0.2, 0.3, 0.5, 1], \"over__sampling_strategy\": [0.1, 0.2, 0.3], \"over__k_neighbors\":[3,5,8], \"under__sampling_strategy\":[0.3, 0.5, 0.7]}\n",
    "clf = GridSearchCV(estimator=pipeline_smote_under, param_grid=p_grid, scoring={'F2':ftwo_scorer}, refit='F2', cv=inner_cv)\n",
    "\n",
    "outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "nested_scores_smote_undersampling = cross_validate(clf, X_features_imputed, y_outcome, \n",
    "                                                   scoring={'F2':ftwo_scorer, 'ROC_AUC':'roc_auc', 'Recall':'recall_macro', 'F1':'f1', 'Brier':\"neg_brier_score\", 'False_neg_scorer':false_neg_scorer, 'False_pos_scorer':false_pos_scorer}, \n",
    "                                                   cv=outer_cv, n_jobs=-1, return_estimator=True, return_indices=True)\n",
    "\n",
    "print(\"HistGradientBoostingClassifier with hyperparameter gridsearch\")\n",
    "\n",
    "roc_auc_metric = np.mean(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "roc_auc_metric_std = np.std(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "print(f'AUC (max): {np.round(roc_auc_metric, 2)} +- {np.round(roc_auc_metric_std, 2)}')\n",
    "\n",
    "f1_score = np.mean(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "f1_score_std = np.std(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "print(f'F1 Score (max): {np.round(f1_score, 2)} +- {np.round(f1_score_std, 2)}')\n",
    "\n",
    "f2_score = np.mean(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "f2_score_std = np.std(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "print(f'F2 Score (max): {np.round(f2_score, 2)} +- {np.round(f2_score_std, 2)}')\n",
    "\n",
    "brier_score = -np.mean(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "brier_score_std = -np.std(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "print(f'Brier Score (min): {np.round(brier_score, 2)} +- {np.round(brier_score_std, 2)}')\n",
    "\n",
    "# test_False_neg_scorer returns the number of test false negatives -> to get a % we need to divide by the number of test samples*100\n",
    "false_neg_score = np.mean(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "false_neg_score_std = np.std(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "print(f'False negative: {int(np.round(false_neg_score, 0))}% +- {int(np.round(false_neg_score_std, 0))}')\n",
    "\n",
    "false_pos_score = np.mean(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "false_pos_score_std = np.std(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "print(f'False positive: {int(np.round(false_pos_score, 0))}% +- {int(np.round(false_pos_score_std, 0))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3414cb4f",
   "metadata": {},
   "source": [
    "#### Confidence intervals with test set bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf61a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_list = []\n",
    "\n",
    "for estimator in nested_scores_smote_undersampling[\"estimator\"]:\n",
    "    best_params_list.append(frozenset(estimator.best_params_.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f602ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Convert dict to a hashable tuple and count occurrences\n",
    "most_common_params = Counter(best_params_list).most_common(1)[0][0]\n",
    "final_params = dict(most_common_params)  # Convert back to dict\n",
    "\n",
    "\n",
    "print(\"Final chosen hyperparameters:\", final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34818bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('over', SMOTE(k_neighbors=3, sampling_strategy=0.3)), ('under', RandomUnderSampler(sampling_strategy=0.7)), ('model', HistGradientBoostingClassifier(learning_rate=0.2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f72859",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(pipeline, X_features_imputed, y_outcome, cv=20, method='predict_proba')[:,1]\n",
    "\n",
    "y_pred_binary = [1 if i>=0.5 else 0 for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7ef0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, confusion_matrix, roc_auc_score, f1_score, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c2a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=12345)\n",
    "idx = np.arange(len(y_outcome))\n",
    "\n",
    "y_pred = np.asarray(y_pred)\n",
    "y_pred_binary = np.asarray(y_pred_binary)\n",
    "y = np.asarray(y_outcome)\n",
    "X_dropped = np.asarray(X_features_imputed)\n",
    "\n",
    "test_roc_auc = []\n",
    "test_f1 = []\n",
    "test_ftwos = []\n",
    "test_brier = []\n",
    "test_false_neg = []\n",
    "test_false_pos = []\n",
    "\n",
    "for i in range(200): # bootstrap with 200 rounds: random sampling with replacement of the predictions\n",
    "\n",
    "    pred_idx = rng.choice(idx, size=len(idx), replace=True)\n",
    "    \n",
    "    roc_auc_test_boot = roc_auc_score(y_score=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    f1_test_boot = f1_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx])\n",
    "    f2_test_boot = fbeta_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx], beta=2)\n",
    "    brier_test_boot = brier_score_loss(y_proba=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    false_neg_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[1,0]\n",
    "    false_pos_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[0,1]\n",
    "    \n",
    "    test_roc_auc.append(roc_auc_test_boot)\n",
    "    test_f1.append(f1_test_boot)\n",
    "    test_ftwos.append(f2_test_boot)\n",
    "    test_brier.append(brier_test_boot)\n",
    "    test_false_neg.append(false_neg_test_boot/len(idx)*100)\n",
    "    test_false_pos.append(false_pos_test_boot/len(idx)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069b5475",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification performance\\n\")\n",
    "\n",
    "bootstrap_roc_auc_test_mean = np.mean(test_roc_auc)\n",
    "ci_lower = np.percentile(test_roc_auc, 2.5)     # 2.5 percentile (alpha=0.025)\n",
    "ci_upper = np.percentile(test_roc_auc, 97.5)\n",
    "print(f\"ROC AUC:         {bootstrap_roc_auc_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f1_test_mean = np.mean(test_f1)\n",
    "ci_lower = np.percentile(test_f1, 2.5)\n",
    "ci_upper = np.percentile(test_f1, 97.5)\n",
    "print(f\"F1:              {bootstrap_f1_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f2_test_mean = np.mean(test_ftwos)\n",
    "ci_lower = np.percentile(test_ftwos, 2.5)\n",
    "ci_upper = np.percentile(test_ftwos, 97.5)\n",
    "print(f\"F2:              {bootstrap_f2_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_brier_test_mean = np.mean(test_brier)\n",
    "ci_lower = np.percentile(test_brier, 2.5)\n",
    "ci_upper = np.percentile(test_brier, 97.5)\n",
    "print(f\"Brier loss:      {bootstrap_brier_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_neg_test_mean = np.mean(test_false_neg)\n",
    "ci_lower = np.percentile(test_false_neg, 2.5)\n",
    "ci_upper = np.percentile(test_false_neg, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_neg_test_mean:.2f}%;  95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_pos_test_mean = np.mean(test_false_pos)\n",
    "ci_lower = np.percentile(test_false_pos, 2.5)\n",
    "ci_upper = np.percentile(test_false_pos, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_pos_test_mean:.2f}%; 95% CI {ci_lower:.2f}-{ci_upper:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d884295",
   "metadata": {},
   "source": [
    "#### Get individual test set samples prediction vs ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bb83b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "pred = nested_scores_smote_undersampling[\"estimator\"][0].predict(X_features_imputed.loc[nested_scores_smote_undersampling[\"indices\"][\"test\"][fold]])\n",
    "y_true = np.asarray(y_outcome)[nested_scores_smote_undersampling[\"indices\"][\"test\"][fold]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21b10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"y_pred: {pred}\")\n",
    "print(f\"y_true: {y_true}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69df7eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find false positive\n",
    "\n",
    "false_negative_index = -1\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i] == 1 and pred[i] == 0:\n",
    "        false_negative_index = nested_scores_smote_undersampling[\"indices\"][\"test\"][fold][i]\n",
    "        print(f\"false negative at index {false_negative_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487cf6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data for this individual\n",
    "print(X.loc[false_negative_index])\n",
    "X.loc[false_negative_index].to_csv(\"patient_inference_results/P0501.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce7448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find false positive\n",
    "\n",
    "false_positive_index = -1\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i] == 0 and pred[i] == 1:\n",
    "        false_positive_index = nested_scores_smote_undersampling[\"indices\"][\"test\"][fold][i]\n",
    "        print(f\"false positive at index {false_positive_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8062b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data for this individual\n",
    "print(X.loc[false_positive_index])\n",
    "#X.loc[false_positive_index].to_csv(\"patient_inference_results/P0498.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a339e7-2ba2-4d5f-a8b8-149d6cb6bd28",
   "metadata": {},
   "source": [
    "### Gradient boosting with traumatrix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af020a91-8d14-47db-9581-eb251ca139fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(DATA_DIRECTORY+\"segmentation_data_anonymized.csv\", usecols=[1]+list(range(16,31)))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5adc3-822b-47f8-bf11-f6bd0d7ee133",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y = get_mortality_6m()\n",
    "\n",
    "# Identify indexes where 'mortality' is NaN in y\n",
    "try:\n",
    "    nan_indexes = y.loc[pd.isna(y[\"mortality\"]), :].index\n",
    "except:\n",
    "    nan_indexes=[]\n",
    "print(f\"Indexes with NaN in 'mortality': {nan_indexes}\")\n",
    "\n",
    "# Drop rows with NaN in y\n",
    "y = y.drop(index=nan_indexes)\n",
    "\n",
    "# Ensure 'name' is the index or used for alignment\n",
    "X = X[~X['name'].isin(y.loc[nan_indexes, 'name'])]\n",
    "\n",
    "# Verify the shapes after cleaning\n",
    "print(f\"Shape of y after cleaning: {y.shape}\")\n",
    "print(f\"Shape of X after cleaning: {X.shape}\")\n",
    "\n",
    "# Vérifiez les valeurs uniques de 'name' dans y\n",
    "print(\"Unique 'name' values in y:\", y['name'].nunique())\n",
    "\n",
    "# Vérifiez les valeurs uniques de 'name' dans X\n",
    "print(\"Unique 'name' values in X:\", X['name'].nunique())\n",
    "\n",
    "# Noms dans y mais pas dans X\n",
    "missing_in_X = set(y['name']) - set(X['name'])\n",
    "print(f\"Names in y but not in X: {missing_in_X}\")\n",
    "\n",
    "# Noms dans X mais pas dans y\n",
    "missing_in_y = set(X['name']) - set(y['name'])\n",
    "print(f\"Names in X but not in y: {missing_in_y}\")\n",
    "\n",
    "# Trouver les noms communs\n",
    "common_names = set(y['name']).intersection(set(X['name']))\n",
    "\n",
    "# Filtrer y et X pour ne garder que les noms communs\n",
    "y = y[y['name'].isin(common_names)]\n",
    "X = X[X['name'].isin(common_names)]\n",
    "\n",
    "# Vérifiez les dimensions après nettoyage\n",
    "print(f\"Shape of y after alignment: {y.shape}\")\n",
    "print(f\"Shape of X after alignment: {X.shape}\")\n",
    "\n",
    "# Check for duplicates in 'name' in y\n",
    "print(\"Number of duplicate names in y:\", y['name'].duplicated().sum())\n",
    "\n",
    "# Check for duplicates in 'name' in X\n",
    "print(\"Number of duplicate names in X:\", X['name'].duplicated().sum())\n",
    "\n",
    "# Remove duplicates from both DataFrames\n",
    "y = y.drop_duplicates(subset=['name'])\n",
    "X = X.drop_duplicates(subset=['name'])\n",
    "\n",
    "# Verify the shapes again\n",
    "print(f\"Shape of y after removing duplicates: {y.shape}\")\n",
    "print(f\"Shape of X after removing duplicates: {X.shape}\")\n",
    "\n",
    "# Check if 'name' values are the same in both DataFrames\n",
    "common_names = set(y['name']) == set(X['name'])\n",
    "print(f\"Are 'name' values aligned between y and X {common_names}\")\n",
    "\n",
    "# Trier y et X par la colonne 'name'\n",
    "y = y.sort_values(by='name').reset_index(drop=True)\n",
    "X = X.sort_values(by='name').reset_index(drop=True)\n",
    "\n",
    "# Vérifier si les noms sont alignés\n",
    "print((y['name'].values == X['name'].values).all())\n",
    "\n",
    "# Drop the 'name' column from X\n",
    "X_features = X.drop(columns=['name'])\n",
    "\n",
    "# imputation with median \n",
    "X_features_imputed = X_features.fillna(X_features.median())\n",
    "\n",
    "# Drop the 'name' column from y (if it exists)\n",
    "y_outcome = y.drop(columns=['name'])\n",
    "\n",
    "# Ensure y_outcome is a 1D array\n",
    "y_outcome = y_outcome.values.ravel()  # Convert to 1D if using pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb3d120-befe-4743-bee7-e49128c254c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_smote_under_traumatrix = Pipeline(steps=[('over', SMOTE()), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "#pipeline_smote_under = Pipeline(steps=[('over', SMOTENC(categorical_features=[\"fracas_du_bassin\", \"amputation\"])), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "\n",
    "\n",
    "inner_cv_traumatrix = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=5, random_state=1)\n",
    "\n",
    "p_grid = {\"model__learning_rate\": [0.01, 0.05, 0.08, 0.1, 0.2, 0.3, 0.5, 1], \"over__sampling_strategy\": [0.1, 0.2, 0.3], \"over__k_neighbors\":[3,5,8], \"under__sampling_strategy\":[0.3, 0.5, 0.7]}\n",
    "clf_traumatrix = GridSearchCV(estimator=pipeline_smote_under_traumatrix, param_grid=p_grid, scoring={'F2':ftwo_scorer}, refit='F2', cv=inner_cv_traumatrix)\n",
    "\n",
    "outer_cv_traumatrix = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "nested_scores_smote_undersampling_traumatrix = cross_validate(clf_traumatrix, X_features_imputed, y_outcome, \n",
    "                                                   scoring={'F2':ftwo_scorer, 'ROC_AUC':'roc_auc', 'Recall':'recall_macro', 'F1':'f1', 'Brier':\"neg_brier_score\", 'False_neg_scorer':false_neg_scorer, 'False_pos_scorer':false_pos_scorer}, \n",
    "                                                   cv=outer_cv_traumatrix, n_jobs=-1, return_estimator=True, return_indices=True)\n",
    "\n",
    "print(\"HistGradientBoostingClassifier with hyperparameter gridsearch\")\n",
    "\n",
    "roc_auc_metric = np.mean(nested_scores_smote_undersampling_traumatrix[\"test_ROC_AUC\"])\n",
    "roc_auc_metric_std = np.std(nested_scores_smote_undersampling_traumatrix[\"test_ROC_AUC\"])\n",
    "print(f'AUC (max): {np.round(roc_auc_metric, 2)} +- {np.round(roc_auc_metric_std, 2)}')\n",
    "\n",
    "f1_score = np.mean(nested_scores_smote_undersampling_traumatrix[\"test_F1\"])\n",
    "f1_score_std = np.std(nested_scores_smote_undersampling_traumatrix[\"test_F1\"])\n",
    "print(f'F1 Score (max): {np.round(f1_score, 2)} +- {np.round(f1_score_std, 2)}')\n",
    "\n",
    "f2_score = np.mean(nested_scores_smote_undersampling_traumatrix[\"test_F2\"])\n",
    "f2_score_std = np.std(nested_scores_smote_undersampling_traumatrix[\"test_F2\"])\n",
    "print(f'F2 Score (max): {np.round(f2_score, 2)} +- {np.round(f2_score_std, 2)}')\n",
    "\n",
    "brier_score = -np.mean(nested_scores_smote_undersampling_traumatrix[\"test_Brier\"])\n",
    "brier_score_std = -np.std(nested_scores_smote_undersampling_traumatrix[\"test_Brier\"])\n",
    "print(f'Brier Score (min): {np.round(brier_score, 2)} +- {np.round(brier_score_std, 2)}')\n",
    "\n",
    "# test_False_neg_scorer returns the number of test false negatives -> to get a % we need to divide by the number of test samples*100\n",
    "false_neg_score = np.mean(nested_scores_smote_undersampling_traumatrix[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "false_neg_score_std = np.std(nested_scores_smote_undersampling_traumatrix[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "print(f'False negative: {int(np.round(false_neg_score, 0))}% +- {int(np.round(false_neg_score_std, 0))}')\n",
    "\n",
    "false_pos_score = np.mean(nested_scores_smote_undersampling_traumatrix[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "false_pos_score_std = np.std(nested_scores_smote_undersampling_traumatrix[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "print(f'False positive: {int(np.round(false_pos_score, 0))}% +- {int(np.round(false_pos_score_std, 0))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe30b5",
   "metadata": {},
   "source": [
    "#### Get individual test set samples prediction vs ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5391cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 2\n",
    "\n",
    "y_true_train_traumatrix = np.asarray(y_outcome)[nested_scores_smote_undersampling_traumatrix[\"indices\"][\"train\"][fold]]\n",
    "y_true_test_traumatrix = np.asarray(y_outcome)[nested_scores_smote_undersampling_traumatrix[\"indices\"][\"test\"][fold]]\n",
    "\n",
    "fitted_traumatrix = nested_scores_smote_undersampling_traumatrix[\"estimator\"][0].fit(X_features_imputed.loc[nested_scores_smote_undersampling_traumatrix[\"indices\"][\"train\"][fold]], y_true_train) #-#=#\n",
    "\n",
    "pred_test_traumatrix = fitted_traumatrix.predict(X_features_imputed.loc[nested_scores_smote_undersampling_traumatrix[\"indices\"][\"test\"][fold]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5995c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"y_pred: {pred_test_traumatrix}\")\n",
    "print(f\"y_true: {y_true_test_traumatrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71dc6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find true positive\n",
    "\n",
    "true_positive_index_traumatrix = -1\n",
    "\n",
    "for i in range(len(y_true_test_traumatrix)):\n",
    "    if y_true_test_traumatrix[i] == 1 and pred_test_traumatrix[i] == 1:\n",
    "        true_positive_index_traumatrix = nested_scores_smote_undersampling[\"indices\"][\"test\"][fold][i]\n",
    "        print(f\"true positive at index {true_positive_index_traumatrix}, i={i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced2743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find true negative\n",
    "\n",
    "true_negative_index_traumatrix = -1\n",
    "\n",
    "for i in range(len(y_true_test_traumatrix)):\n",
    "    if y_true_test_traumatrix[i] == 0 and pred_test_traumatrix[i] == 0:\n",
    "        true_negative_index_traumatrix = nested_scores_smote_undersampling_traumatrix[\"indices\"][\"test\"][fold][i]\n",
    "        print(f\"true negative at index {true_negative_index_traumatrix}, i={i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c252ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find false negative\n",
    "\n",
    "false_negative_index_traumatrix = -1\n",
    "\n",
    "for i in range(len(y_true_test_traumatrix)):\n",
    "    if y_true_test_traumatrix[i] == 1 and pred_test_traumatrix[i] == 0:\n",
    "        false_negative_index_traumatrix = nested_scores_smote_undersampling_traumatrix[\"indices\"][\"test\"][fold][i]\n",
    "        print(f\"false negative at index {false_negative_index_traumatrix}, i={i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa30f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find false positive\n",
    "\n",
    "false_positive_index_traumatrix = -1\n",
    "\n",
    "for i in range(len(y_true_test_traumatrix)):\n",
    "    if y_true_test_traumatrix[i] == 0 and pred_test_traumatrix[i] == 1:\n",
    "        false_positive_index_traumatrix = nested_scores_smote_undersampling_traumatrix[\"indices\"][\"test\"][fold][i]\n",
    "        print(f\"false positive at index {false_positive_index_traumatrix}, i={i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea17f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data for this individual\n",
    "print(X_volumes_clinical.loc[24])\n",
    "#X_volumes_clinical.loc[329].to_csv(\"patient_inference_results/P0010.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd83c2",
   "metadata": {},
   "source": [
    "#### SHAP explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6889d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitted.best_estimator_[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9374163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(fitted.best_estimator_[\"model\"]) \n",
    "shap_values2 = explainer(X_features_imputed.loc[nested_scores_smote_undersampling[\"indices\"][\"test\"][fold]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4cd541",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5a8f4",
   "metadata": {},
   "source": [
    "#### Confidence intervals with test set bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_list = []\n",
    "\n",
    "for estimator in nested_scores_smote_undersampling[\"estimator\"]:\n",
    "    best_params_list.append(frozenset(estimator.best_params_.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db885c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Convert dict to a hashable tuple and count occurrences\n",
    "most_common_params = Counter(best_params_list).most_common(1)[0][0]\n",
    "final_params = dict(most_common_params)  # Convert back to dict\n",
    "\n",
    "\n",
    "print(\"Final chosen hyperparameters:\", final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f60b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('over', SMOTE(k_neighbors=3, sampling_strategy=0.3)), ('under', RandomUnderSampler(sampling_strategy=0.7)), ('model', HistGradientBoostingClassifier(learning_rate=0.2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9671985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(pipeline, X_features_imputed, y_outcome, cv=20, method='predict_proba')[:,1]\n",
    "\n",
    "y_pred_binary = [1 if i>=0.5 else 0 for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46550f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, confusion_matrix, roc_auc_score, f1_score, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0bc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=12345)\n",
    "idx = np.arange(len(y_outcome))\n",
    "\n",
    "y_pred = np.asarray(y_pred)\n",
    "y_pred_binary = np.asarray(y_pred_binary)\n",
    "y = np.asarray(y_outcome)\n",
    "X_dropped = np.asarray(X_features_imputed)\n",
    "\n",
    "test_roc_auc = []\n",
    "test_f1 = []\n",
    "test_ftwos = []\n",
    "test_brier = []\n",
    "test_false_neg = []\n",
    "test_false_pos = []\n",
    "\n",
    "for i in range(200): # bootstrap with 200 rounds: random sampling with replacement of the predictions\n",
    "\n",
    "    pred_idx = rng.choice(idx, size=len(idx), replace=True)\n",
    "    \n",
    "    roc_auc_test_boot = roc_auc_score(y_score=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    f1_test_boot = f1_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx])\n",
    "    f2_test_boot = fbeta_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx], beta=2)\n",
    "    brier_test_boot = brier_score_loss(y_proba=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    false_neg_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[1,0]\n",
    "    false_pos_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[0,1]\n",
    "    \n",
    "    test_roc_auc.append(roc_auc_test_boot)\n",
    "    test_f1.append(f1_test_boot)\n",
    "    test_ftwos.append(f2_test_boot)\n",
    "    test_brier.append(brier_test_boot)\n",
    "    test_false_neg.append(false_neg_test_boot/len(idx)*100)\n",
    "    test_false_pos.append(false_pos_test_boot/len(idx)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification performance\\n\")\n",
    "\n",
    "bootstrap_roc_auc_test_mean = np.mean(test_roc_auc)\n",
    "ci_lower = np.percentile(test_roc_auc, 2.5)     # 2.5 percentile (alpha=0.025)\n",
    "ci_upper = np.percentile(test_roc_auc, 97.5)\n",
    "print(f\"ROC AUC:         {bootstrap_roc_auc_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f1_test_mean = np.mean(test_f1)\n",
    "ci_lower = np.percentile(test_f1, 2.5)\n",
    "ci_upper = np.percentile(test_f1, 97.5)\n",
    "print(f\"F1:              {bootstrap_f1_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f2_test_mean = np.mean(test_ftwos)\n",
    "ci_lower = np.percentile(test_ftwos, 2.5)\n",
    "ci_upper = np.percentile(test_ftwos, 97.5)\n",
    "print(f\"F2:              {bootstrap_f2_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_brier_test_mean = np.mean(test_brier)\n",
    "ci_lower = np.percentile(test_brier, 2.5)\n",
    "ci_upper = np.percentile(test_brier, 97.5)\n",
    "print(f\"Brier loss:      {bootstrap_brier_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_neg_test_mean = np.mean(test_false_neg)\n",
    "ci_lower = np.percentile(test_false_neg, 2.5)\n",
    "ci_upper = np.percentile(test_false_neg, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_neg_test_mean:.2f}%;  95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_pos_test_mean = np.mean(test_false_pos)\n",
    "ci_lower = np.percentile(test_false_pos, 2.5)\n",
    "ci_upper = np.percentile(test_false_pos, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_pos_test_mean:.2f}%; 95% CI {ci_lower:.2f}-{ci_upper:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d926f42f",
   "metadata": {},
   "source": [
    "#### Confidence intervals with test set bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2921b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_list_traumatrix = []\n",
    "\n",
    "for estimator in nested_scores_smote_undersampling_traumatrix[\"estimator\"]:\n",
    "    best_params_list_traumatrix.append(frozenset(estimator.best_params_.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542acbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Convert dict to a hashable tuple and count occurrences\n",
    "most_common_params_traumatrix = Counter(best_params_list_traumatrix).most_common(1)[0][0]\n",
    "final_params_traumatrix = dict(most_common_params_traumatrix)  # Convert back to dict\n",
    "\n",
    "\n",
    "print(\"Final chosen hyperparameters:\", final_params_traumatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db86213",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_traumatrix = Pipeline(steps=[('over', SMOTE(k_neighbors=8, sampling_strategy=0.2)), ('under', RandomUnderSampler(sampling_strategy=0.7)), ('model', HistGradientBoostingClassifier(learning_rate=0.08))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_traumatrix = cross_val_predict(pipeline_traumatrix, X_features_imputed, y_outcome, cv=20, method='predict_proba')[:,1]\n",
    "\n",
    "y_pred_binary_traumatrix = [1 if i>=0.5 else 0 for i in y_pred_traumatrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d95795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, confusion_matrix, roc_auc_score, f1_score, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20353d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=12345)\n",
    "idx = np.arange(len(y_outcome))\n",
    "\n",
    "y_pred_traumatrix = np.asarray(y_pred_traumatrix)\n",
    "y_pred_binary_traumatrix = np.asarray(y_pred_binary_traumatrix)\n",
    "y = np.asarray(y_outcome)\n",
    "X_dropped = np.asarray(X_features_imputed)\n",
    "\n",
    "test_roc_auc = []\n",
    "test_f1 = []\n",
    "test_ftwos = []\n",
    "test_brier = []\n",
    "test_false_neg = []\n",
    "test_false_pos = []\n",
    "\n",
    "for i in range(200): # bootstrap with 200 rounds: random sampling with replacement of the predictions\n",
    "\n",
    "    pred_idx = rng.choice(idx, size=len(idx), replace=True)\n",
    "    \n",
    "    roc_auc_test_boot = roc_auc_score(y_score=y_pred_traumatrix[pred_idx], y_true=y[pred_idx])\n",
    "    f1_test_boot = f1_score(y_pred=y_pred_binary_traumatrix[pred_idx], y_true=y[pred_idx])\n",
    "    f2_test_boot = fbeta_score(y_pred=y_pred_binary_traumatrix[pred_idx], y_true=y[pred_idx], beta=2)\n",
    "    brier_test_boot = brier_score_loss(y_proba=y_pred_traumatrix[pred_idx], y_true=y[pred_idx])\n",
    "    false_neg_test_boot = confusion_matrix(y[pred_idx], y_pred_binary_traumatrix[pred_idx])[1,0]\n",
    "    false_pos_test_boot = confusion_matrix(y[pred_idx], y_pred_binary_traumatrix[pred_idx])[0,1]\n",
    "    \n",
    "    test_roc_auc.append(roc_auc_test_boot)\n",
    "    test_f1.append(f1_test_boot)\n",
    "    test_ftwos.append(f2_test_boot)\n",
    "    test_brier.append(brier_test_boot)\n",
    "    test_false_neg.append(false_neg_test_boot/len(idx)*100)\n",
    "    test_false_pos.append(false_pos_test_boot/len(idx)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification performance\\n\")\n",
    "\n",
    "bootstrap_roc_auc_test_mean = np.mean(test_roc_auc)\n",
    "ci_lower = np.percentile(test_roc_auc, 2.5)     # 2.5 percentile (alpha=0.025)\n",
    "ci_upper = np.percentile(test_roc_auc, 97.5)\n",
    "print(f\"ROC AUC:         {bootstrap_roc_auc_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f1_test_mean = np.mean(test_f1)\n",
    "ci_lower = np.percentile(test_f1, 2.5)\n",
    "ci_upper = np.percentile(test_f1, 97.5)\n",
    "print(f\"F1:              {bootstrap_f1_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f2_test_mean = np.mean(test_ftwos)\n",
    "ci_lower = np.percentile(test_ftwos, 2.5)\n",
    "ci_upper = np.percentile(test_ftwos, 97.5)\n",
    "print(f\"F2:              {bootstrap_f2_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_brier_test_mean = np.mean(test_brier)\n",
    "ci_lower = np.percentile(test_brier, 2.5)\n",
    "ci_upper = np.percentile(test_brier, 97.5)\n",
    "print(f\"Brier loss:      {bootstrap_brier_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_neg_test_mean = np.mean(test_false_neg)\n",
    "ci_lower = np.percentile(test_false_neg, 2.5)\n",
    "ci_upper = np.percentile(test_false_neg, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_neg_test_mean:.2f}%;  95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_pos_test_mean = np.mean(test_false_pos)\n",
    "ci_lower = np.percentile(test_false_pos, 2.5)\n",
    "ci_upper = np.percentile(test_false_pos, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_pos_test_mean:.2f}%; 95% CI {ci_lower:.2f}-{ci_upper:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb29faa-0b5a-473d-bebc-bacc6b45dd60",
   "metadata": {},
   "source": [
    "### Gradient boosting with all prehospital features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5afc49d2-47e6-4eab-ab8b-3f9c0fb8cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run preprocessing outcome mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ac410d-f94e-4ff9-92a9-29bb34fb3c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>name</th>\n",
       "      <th>Date Naissance</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sexe</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Entrée venue</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Exclusion</th>\n",
       "      <th>...</th>\n",
       "      <th>score_glasgow_initial</th>\n",
       "      <th>score_glasgow_moteur_initial</th>\n",
       "      <th>anomalie_pupillaire_prehospitalier</th>\n",
       "      <th>frequence_cardiaque_FC_arrivee_du_smur</th>\n",
       "      <th>arret_cardio_respiratoire_massage</th>\n",
       "      <th>penetrant_objet</th>\n",
       "      <th>ischemie_du_membre</th>\n",
       "      <th>hemorragie_externe</th>\n",
       "      <th>amputation</th>\n",
       "      <th>outcome_neurochir_pic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P0000</td>\n",
       "      <td>11/19/1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2.000010e+12</td>\n",
       "      <td>8/5/2020 21:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>P0001</td>\n",
       "      <td>11/21/1968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2.000010e+12</td>\n",
       "      <td>8/6/2020 11:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>P0002</td>\n",
       "      <td>6/14/1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2.000010e+12</td>\n",
       "      <td>8/7/2020 21:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>P0003</td>\n",
       "      <td>8/5/1978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>2.000010e+12</td>\n",
       "      <td>8/8/2020 19:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>P0004</td>\n",
       "      <td>11/17/1986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2.000010e+12</td>\n",
       "      <td>8/9/2020 2:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0_x   name Date Naissance  Age Sexe         Venue  \\\n",
       "0           0             0  P0000     11/19/1941  NaN    M  2.000010e+12   \n",
       "1           1             1  P0001     11/21/1968  NaN    M  2.000010e+12   \n",
       "2           2             2  P0002      6/14/1997  NaN    M  2.000010e+12   \n",
       "3           3             3  P0003       8/5/1978  NaN    F  2.000010e+12   \n",
       "4           4             4  P0004     11/17/1986  NaN    M  2.000010e+12   \n",
       "\n",
       "     Entrée venue  Unnamed: 9 Exclusion  ... score_glasgow_initial  \\\n",
       "0  8/5/2020 21:36         NaN       NaN  ...                  15.0   \n",
       "1  8/6/2020 11:50         NaN       NaN  ...                  15.0   \n",
       "2  8/7/2020 21:31         NaN       NaN  ...                  15.0   \n",
       "3  8/8/2020 19:57         NaN       NaN  ...                  14.0   \n",
       "4   8/9/2020 2:19         NaN       NaN  ...                  15.0   \n",
       "\n",
       "  score_glasgow_moteur_initial anomalie_pupillaire_prehospitalier  \\\n",
       "0                          6.0                                0.0   \n",
       "1                          6.0                                0.0   \n",
       "2                          6.0                                0.0   \n",
       "3                          6.0                                0.0   \n",
       "4                          6.0                                0.0   \n",
       "\n",
       "   frequence_cardiaque_FC_arrivee_du_smur arret_cardio_respiratoire_massage  \\\n",
       "0                                   137.0                               0.0   \n",
       "1                                    56.0                               0.0   \n",
       "2                                   100.0                               0.0   \n",
       "3                                   120.0                               0.0   \n",
       "4                                   107.0                               0.0   \n",
       "\n",
       "  penetrant_objet ischemie_du_membre hemorragie_externe amputation  \\\n",
       "0             0.0                0.0                0.0        0.0   \n",
       "1             0.0                0.0                0.0        0.0   \n",
       "2             0.0                0.0                0.0        0.0   \n",
       "3             0.0                0.0                0.0        0.0   \n",
       "4             0.0                0.0                0.0        0.0   \n",
       "\n",
       "  outcome_neurochir_pic  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_full = pd.read_csv(DATA_DIRECTORY+\"final_database_clinical_segmentation.csv\")\n",
    "data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b59844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns 16 to 36\n",
    "X_prehosp = data_full.iloc[:, 15:35]\n",
    "\n",
    "# Convert all columns to numeric, replacing non-numeric values and empty strings with NaN\n",
    "X_prehosp = X_prehosp.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Include column name\n",
    "X_prehosp = pd.concat([X_prehosp, data_full.iloc[:, 2]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f19d33c-379d-48a5-bbd6-e1a8886d5ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values per column:\n",
      "PAS  SMUR                   40\n",
      "PAD  SMUR                   49\n",
      "FC SMUR                     42\n",
      "FR SMUR                    485\n",
      "Shock Index SMUR            55\n",
      "GCS SMUR                    17\n",
      "GCS (M) SMUR                30\n",
      "Hémocue SMUR               243\n",
      "Shock Index inversé         54\n",
      "Shock index diastolique     62\n",
      "Anomalie pupille SMUR       17\n",
      "Fracas bassin               14\n",
      "Amputation                  12\n",
      "ACR SMUR                    11\n",
      "Hémorragie ext SMUR         12\n",
      "Ischémie                    12\n",
      "Intubation prehosp          11\n",
      "Expansion volémique         20\n",
      "OsmoTH prehosp              11\n",
      "Vasopresseur prehosp        12\n",
      "name                         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAS  SMUR</th>\n",
       "      <th>PAD  SMUR</th>\n",
       "      <th>FC SMUR</th>\n",
       "      <th>FR SMUR</th>\n",
       "      <th>Shock Index SMUR</th>\n",
       "      <th>GCS SMUR</th>\n",
       "      <th>GCS (M) SMUR</th>\n",
       "      <th>Hémocue SMUR</th>\n",
       "      <th>Shock Index inversé</th>\n",
       "      <th>Shock index diastolique</th>\n",
       "      <th>...</th>\n",
       "      <th>Fracas bassin</th>\n",
       "      <th>Amputation</th>\n",
       "      <th>ACR SMUR</th>\n",
       "      <th>Hémorragie ext SMUR</th>\n",
       "      <th>Ischémie</th>\n",
       "      <th>Intubation prehosp</th>\n",
       "      <th>Expansion volémique</th>\n",
       "      <th>OsmoTH prehosp</th>\n",
       "      <th>Vasopresseur prehosp</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.72</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.64</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.19</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P0004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PAS  SMUR   PAD  SMUR   FC SMUR   FR SMUR  Shock Index SMUR  GCS SMUR   \\\n",
       "0       190.0       103.0     137.0      NaN              0.72       15.0   \n",
       "1        87.0        49.0      56.0      NaN              0.64       15.0   \n",
       "2       100.0        60.0     100.0     17.0              1.00       15.0   \n",
       "3       101.0        64.0     120.0      NaN              1.19       14.0   \n",
       "4       110.0        71.0     107.0     18.0              0.97       15.0   \n",
       "\n",
       "   GCS (M) SMUR   Hémocue SMUR   Shock Index inversé  Shock index diastolique  \\\n",
       "0            6.0            NaN                 1.39                     1.33   \n",
       "1            6.0            NaN                 1.55                     1.14   \n",
       "2            6.0            NaN                 1.00                     1.67   \n",
       "3            6.0           13.1                 0.84                     1.88   \n",
       "4            6.0           15.8                 1.03                     1.51   \n",
       "\n",
       "   ...  Fracas bassin  Amputation  ACR SMUR  Hémorragie ext SMUR  Ischémie  \\\n",
       "0  ...            0.0         0.0       0.0                  0.0       0.0   \n",
       "1  ...            0.0         0.0       0.0                  0.0       0.0   \n",
       "2  ...            0.0         0.0       0.0                  0.0       0.0   \n",
       "3  ...            0.0         0.0       0.0                  0.0       0.0   \n",
       "4  ...            0.0         0.0       0.0                  0.0       0.0   \n",
       "\n",
       "   Intubation prehosp  Expansion volémique  OsmoTH prehosp  \\\n",
       "0                 0.0                500.0             0.0   \n",
       "1                 0.0                250.0             0.0   \n",
       "2                 0.0                250.0             0.0   \n",
       "3                 0.0                250.0             0.0   \n",
       "4                 0.0                500.0             0.0   \n",
       "\n",
       "   Vasopresseur prehosp   name  \n",
       "0                   0.0  P0000  \n",
       "1                   0.0  P0001  \n",
       "2                   0.0  P0002  \n",
       "3                   0.0  P0003  \n",
       "4                   0.0  P0004  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Verify if there are NaN values\n",
    "print(f\"Number of NaN values per column:\\n{X_prehosp.isna().sum()}\")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "X_prehosp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b908a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_prehosp.copy()\n",
    "y = get_mortality_6m()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc8412e1-1a5b-4602-8cff-cef01799c912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes with NaN in 'mortality': Index([], dtype='int64')\n",
      "Shape of y after cleaning: (566, 2)\n",
      "Shape of X after cleaning: (534, 21)\n",
      "Unique 'name' values in y: 562\n",
      "Unique 'name' values in X: 534\n",
      "Names in y but not in X: {'P0349', 'P0518', 'P0155', 'P0150', 'P0383', 'P0224', 'P0217', 'P0564', 'P0532', 'P0327', 'P0147', 'P0207', 'P0018', 'P0195', 'P0430', 'P0239', 'P0149', 'P0480', 'P0083', 'P0369', 'P0422', 'P0412', 'P0111', 'P0356', 'P0010', 'P0527', 'P0343', 'P0491'}\n",
      "Names in X but not in y: set()\n",
      "Shape of y after alignment: (536, 2)\n",
      "Shape of X after alignment: (534, 21)\n",
      "Number of duplicate names in y: 2\n",
      "Number of duplicate names in X: 0\n",
      "Shape of y after removing duplicates: (534, 2)\n",
      "Shape of X after removing duplicates: (534, 21)\n",
      "Are 'name' values aligned between y and X True\n"
     ]
    }
   ],
   "source": [
    "# Identify indexes where 'mortality' is NaN in y\n",
    "nan_indexes = y.loc[pd.isna(y[\"mortality\"]), :].index\n",
    "print(f\"Indexes with NaN in 'mortality': {nan_indexes}\")\n",
    "\n",
    "# Drop rows with NaN in y\n",
    "y = y.drop(index=nan_indexes)\n",
    "\n",
    "# Ensure 'name' is the index or used for alignment\n",
    "X = X[~X['name'].isin(y.loc[nan_indexes, 'name'])]\n",
    "\n",
    "# Verify the shapes after cleaning\n",
    "print(f\"Shape of y after cleaning: {y.shape}\")\n",
    "print(f\"Shape of X after cleaning: {X.shape}\")\n",
    "\n",
    "# Vérifiez les valeurs uniques de 'name' dans y\n",
    "print(\"Unique 'name' values in y:\", y['name'].nunique())\n",
    "\n",
    "# Vérifiez les valeurs uniques de 'name' dans X\n",
    "print(\"Unique 'name' values in X:\", X['name'].nunique())\n",
    "\n",
    "# Noms dans y mais pas dans X\n",
    "missing_in_X = set(y['name']) - set(X['name'])\n",
    "print(f\"Names in y but not in X: {missing_in_X}\")\n",
    "\n",
    "# Noms dans X mais pas dans y\n",
    "missing_in_y = set(X['name']) - set(y['name'])\n",
    "print(f\"Names in X but not in y: {missing_in_y}\")\n",
    "\n",
    "# Trouver les noms communs\n",
    "common_names = set(y['name']).intersection(set(X['name']))\n",
    "\n",
    "# Filtrer y et X pour ne garder que les noms communs\n",
    "y = y[y['name'].isin(common_names)]\n",
    "X = X[X['name'].isin(common_names)]\n",
    "\n",
    "# Vérifiez les dimensions après nettoyage\n",
    "print(f\"Shape of y after alignment: {y.shape}\")\n",
    "print(f\"Shape of X after alignment: {X.shape}\")\n",
    "\n",
    "# Check for duplicates in 'name' in y\n",
    "print(\"Number of duplicate names in y:\", y['name'].duplicated().sum())\n",
    "\n",
    "# Check for duplicates in 'name' in X\n",
    "print(\"Number of duplicate names in X:\", X['name'].duplicated().sum())\n",
    "\n",
    "# Remove duplicates from both DataFrames\n",
    "y = y.drop_duplicates(subset=['name'])\n",
    "X = X.drop_duplicates(subset=['name'])\n",
    "\n",
    "# Verify the shapes again\n",
    "print(f\"Shape of y after removing duplicates: {y.shape}\")\n",
    "print(f\"Shape of X after removing duplicates: {X.shape}\")\n",
    "\n",
    "# Check if 'name' values are the same in both DataFrames\n",
    "common_names = set(y['name']) == set(X['name'])\n",
    "print(f\"Are 'name' values aligned between y and X {common_names}\")\n",
    "\n",
    "# Drop the 'name' column from X_volumes_clinical_with_outcome\n",
    "X_features = X.drop(columns=['name'])\n",
    "\n",
    "# imputation with median \n",
    "X_features_imputed = X_features.fillna(X_features.median())\n",
    "\n",
    "# Drop the 'name' column from y (if it exists)\n",
    "y_outcome = y.drop(columns=['name'])\n",
    "\n",
    "# Ensure y_outcome is a 1D array\n",
    "y_outcome = y_outcome.values.ravel()  # Convert to 1D if using pandas DataFrame\n",
    "\n",
    "FOLDS = 5\n",
    "N_REPEATS = 3\n",
    "nb_total_samples = len(y_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fcf9e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41949b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5147e5e0-3e66-448b-b6c7-b520fd5a1ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoostingClassifier with hyperparameter gridsearch\n",
      "AUC (max): 0.93 +- 0.05\n",
      "F1 Score (max): 0.53 +- 0.1\n",
      "F2 Score (max): 0.62 +- 0.12\n",
      "Brier Score (min): 0.07 +- -0.02\n",
      "False negative: 2% +- 1\n",
      "False positive: 6% +- 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline_smote_under = Pipeline(steps=[('over', SMOTE()), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "#pipeline_smote_under = Pipeline(steps=[('over', SMOTENC(categorical_features=[\"fracas_du_bassin\", \"amputation\"])), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "\n",
    "\n",
    "inner_cv = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=5, random_state=1)\n",
    "\n",
    "p_grid = {\"model__learning_rate\": [0.01, 0.05, 0.08, 0.1, 0.2, 0.3, 0.5, 1], \"over__sampling_strategy\": [0.1, 0.2, 0.3], \"over__k_neighbors\":[3,5,8], \"under__sampling_strategy\":[0.3, 0.5, 0.7]}\n",
    "clf = GridSearchCV(estimator=pipeline_smote_under, param_grid=p_grid, scoring={'F2':ftwo_scorer}, refit='F2', cv=inner_cv)\n",
    "\n",
    "outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "nested_scores_smote_undersampling = cross_validate(clf, X_features_imputed, y_outcome, \n",
    "                                                scoring={'F2':ftwo_scorer, 'ROC_AUC':'roc_auc', 'Recall':'recall_macro', 'F1':'f1', 'Brier':\"neg_brier_score\", 'False_neg_scorer':false_neg_scorer, 'False_pos_scorer':false_pos_scorer}, \n",
    "                                                cv=outer_cv, n_jobs=-1, return_estimator=True, return_indices=True)\n",
    "\n",
    "print(\"HistGradientBoostingClassifier with hyperparameter gridsearch\")\n",
    "\n",
    "roc_auc_metric = np.mean(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "roc_auc_metric_std = np.std(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "print(f'AUC (max): {np.round(roc_auc_metric, 2)} +- {np.round(roc_auc_metric_std, 2)}')\n",
    "\n",
    "f1_score = np.mean(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "f1_score_std = np.std(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "print(f'F1 Score (max): {np.round(f1_score, 2)} +- {np.round(f1_score_std, 2)}')\n",
    "\n",
    "f2_score = np.mean(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "f2_score_std = np.std(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "print(f'F2 Score (max): {np.round(f2_score, 2)} +- {np.round(f2_score_std, 2)}')\n",
    "\n",
    "brier_score = -np.mean(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "brier_score_std = -np.std(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "print(f'Brier Score (min): {np.round(brier_score, 2)} +- {np.round(brier_score_std, 2)}')\n",
    "\n",
    "# test_False_neg_scorer returns the number of test false negatives -> to get a % we need to divide by the number of test samples*100\n",
    "false_neg_score = np.mean(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "false_neg_score_std = np.std(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "print(f'False negative: {int(np.round(false_neg_score, 0))}% +- {int(np.round(false_neg_score_std, 0))}')\n",
    "\n",
    "false_pos_score = np.mean(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "false_pos_score_std = np.std(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "print(f'False positive: {int(np.round(false_pos_score, 0))}% +- {int(np.round(false_pos_score_std, 0))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ad0b8",
   "metadata": {},
   "source": [
    "#### Confidence intervals with test set bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac1fda35",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_list = []\n",
    "\n",
    "for estimator in nested_scores_smote_undersampling[\"estimator\"]:\n",
    "    best_params_list.append(frozenset(estimator.best_params_.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af383618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final chosen hyperparameters: {'model__learning_rate': 0.01, 'under__sampling_strategy': 0.7, 'over__sampling_strategy': 0.2, 'over__k_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Convert dict to a hashable tuple and count occurrences\n",
    "most_common_params = Counter(best_params_list).most_common(1)[0][0]\n",
    "final_params = dict(most_common_params)  # Convert back to dict\n",
    "\n",
    "\n",
    "print(\"Final chosen hyperparameters:\", final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c18cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('over', SMOTE(k_neighbors=5, sampling_strategy=0.2)), ('under', RandomUnderSampler(sampling_strategy=0.7)), ('model', HistGradientBoostingClassifier(learning_rate=0.01))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92a390d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(pipeline, X_features_imputed, y_outcome, cv=20, method='predict_proba')[:,1]\n",
    "\n",
    "y_pred_binary = [1 if i>=0.5 else 0 for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "974f6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, confusion_matrix, roc_auc_score, f1_score, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3098dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=12345)\n",
    "idx = np.arange(len(y_outcome))\n",
    "\n",
    "y_pred = np.asarray(y_pred)\n",
    "y_pred_binary = np.asarray(y_pred_binary)\n",
    "y = np.asarray(y_outcome)\n",
    "X_dropped = np.asarray(X_features_imputed)\n",
    "\n",
    "test_roc_auc = []\n",
    "test_f1 = []\n",
    "test_ftwos = []\n",
    "test_brier = []\n",
    "test_false_neg = []\n",
    "test_false_pos = []\n",
    "\n",
    "for i in range(200): # bootstrap with 200 rounds: random sampling with replacement of the predictions\n",
    "\n",
    "    pred_idx = rng.choice(idx, size=len(idx), replace=True)\n",
    "    \n",
    "    roc_auc_test_boot = roc_auc_score(y_score=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    f1_test_boot = f1_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx])\n",
    "    f2_test_boot = fbeta_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx], beta=2)\n",
    "    brier_test_boot = brier_score_loss(y_proba=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    false_neg_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[1,0]\n",
    "    false_pos_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[0,1]\n",
    "    \n",
    "    test_roc_auc.append(roc_auc_test_boot)\n",
    "    test_f1.append(f1_test_boot)\n",
    "    test_ftwos.append(f2_test_boot)\n",
    "    test_brier.append(brier_test_boot)\n",
    "    test_false_neg.append(false_neg_test_boot/len(idx)*100)\n",
    "    test_false_pos.append(false_pos_test_boot/len(idx)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "566b3caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance\n",
      "\n",
      "ROC AUC:         0.92;   95% CI 0.87-0.97\n",
      "F1:              0.55;   95% CI 0.42-0.66\n",
      "F2:              0.64;   95% CI 0.51-0.75\n",
      "Brier loss:      0.07;   95% CI 0.06-0.08\n",
      "False negatives: 1.67%;  95% CI 0.75-2.81\n",
      "False negatives: 5.40%; 95% CI 3.37-7.49\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification performance\\n\")\n",
    "\n",
    "bootstrap_roc_auc_test_mean = np.mean(test_roc_auc)\n",
    "ci_lower = np.percentile(test_roc_auc, 2.5)     # 2.5 percentile (alpha=0.025)\n",
    "ci_upper = np.percentile(test_roc_auc, 97.5)\n",
    "print(f\"ROC AUC:         {bootstrap_roc_auc_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f1_test_mean = np.mean(test_f1)\n",
    "ci_lower = np.percentile(test_f1, 2.5)\n",
    "ci_upper = np.percentile(test_f1, 97.5)\n",
    "print(f\"F1:              {bootstrap_f1_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f2_test_mean = np.mean(test_ftwos)\n",
    "ci_lower = np.percentile(test_ftwos, 2.5)\n",
    "ci_upper = np.percentile(test_ftwos, 97.5)\n",
    "print(f\"F2:              {bootstrap_f2_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_brier_test_mean = np.mean(test_brier)\n",
    "ci_lower = np.percentile(test_brier, 2.5)\n",
    "ci_upper = np.percentile(test_brier, 97.5)\n",
    "print(f\"Brier loss:      {bootstrap_brier_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_neg_test_mean = np.mean(test_false_neg)\n",
    "ci_lower = np.percentile(test_false_neg, 2.5)\n",
    "ci_upper = np.percentile(test_false_neg, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_neg_test_mean:.2f}%;  95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_pos_test_mean = np.mean(test_false_pos)\n",
    "ci_lower = np.percentile(test_false_pos, 2.5)\n",
    "ci_upper = np.percentile(test_false_pos, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_pos_test_mean:.2f}%; 95% CI {ci_lower:.2f}-{ci_upper:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797908a5",
   "metadata": {},
   "source": [
    "### Gradient boosting with prehospital + segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run preprocessing outcome mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "75324b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns 16 to 36\n",
    "X_prehosp_and_segmentation = data_full.iloc[:, 15:35]\n",
    "\n",
    "# Add segmentation columns\n",
    "X_prehosp_and_segmentation = pd.concat([X_prehosp_and_segmentation, data_full.iloc[:, 101:115]], axis=1)\n",
    "\n",
    "# Convert all columns to numeric, replacing non-numeric values and empty strings with NaN\n",
    "X_prehosp_and_segmentation = X_prehosp_and_segmentation.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Include column name\n",
    "X_prehosp_and_segmentation = pd.concat([X_prehosp_and_segmentation, data_full.iloc[:, 2]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "172f5ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values per column:\n",
      "PAS  SMUR                    40\n",
      "PAD  SMUR                    49\n",
      "FC SMUR                      42\n",
      "FR SMUR                     485\n",
      "Shock Index SMUR             55\n",
      "GCS SMUR                     17\n",
      "GCS (M) SMUR                 30\n",
      "Hémocue SMUR                243\n",
      "Shock Index inversé          54\n",
      "Shock index diastolique      62\n",
      "Anomalie pupille SMUR        17\n",
      "Fracas bassin                14\n",
      "Amputation                   12\n",
      "ACR SMUR                     11\n",
      "Hémorragie ext SMUR          12\n",
      "Ischémie                     12\n",
      "Intubation prehosp           11\n",
      "Expansion volémique          20\n",
      "OsmoTH prehosp               11\n",
      "Vasopresseur prehosp         12\n",
      "supratentorial_IPH            0\n",
      "supratentorial_SAH            0\n",
      "supratentorial_Petechiae      0\n",
      "supratentorial_Edema          0\n",
      "infratentorial_IPH            0\n",
      "infratentorial_SAH            0\n",
      "infratentorial_Petechiae      0\n",
      "infratentorial_Edema          0\n",
      "brainstem_IPH                 0\n",
      "brainstem_SAH                 0\n",
      "brainstem_Petechiae           0\n",
      "brainstem_Edema               0\n",
      "SDH_y                         0\n",
      "EDH                           0\n",
      "name                          0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAS  SMUR</th>\n",
       "      <th>PAD  SMUR</th>\n",
       "      <th>FC SMUR</th>\n",
       "      <th>FR SMUR</th>\n",
       "      <th>Shock Index SMUR</th>\n",
       "      <th>GCS SMUR</th>\n",
       "      <th>GCS (M) SMUR</th>\n",
       "      <th>Hémocue SMUR</th>\n",
       "      <th>Shock Index inversé</th>\n",
       "      <th>Shock index diastolique</th>\n",
       "      <th>...</th>\n",
       "      <th>infratentorial_SAH</th>\n",
       "      <th>infratentorial_Petechiae</th>\n",
       "      <th>infratentorial_Edema</th>\n",
       "      <th>brainstem_IPH</th>\n",
       "      <th>brainstem_SAH</th>\n",
       "      <th>brainstem_Petechiae</th>\n",
       "      <th>brainstem_Edema</th>\n",
       "      <th>SDH_y</th>\n",
       "      <th>EDH</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.72</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2476</td>\n",
       "      <td>229</td>\n",
       "      <td>P0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.64</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.14</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>P0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>11685</td>\n",
       "      <td>P0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.19</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>P0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "      <td>P0004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PAS  SMUR   PAD  SMUR   FC SMUR   FR SMUR  Shock Index SMUR  GCS SMUR   \\\n",
       "0       190.0       103.0     137.0      NaN              0.72       15.0   \n",
       "1        87.0        49.0      56.0      NaN              0.64       15.0   \n",
       "2       100.0        60.0     100.0     17.0              1.00       15.0   \n",
       "3       101.0        64.0     120.0      NaN              1.19       14.0   \n",
       "4       110.0        71.0     107.0     18.0              0.97       15.0   \n",
       "\n",
       "   GCS (M) SMUR   Hémocue SMUR   Shock Index inversé  Shock index diastolique  \\\n",
       "0            6.0            NaN                 1.39                     1.33   \n",
       "1            6.0            NaN                 1.55                     1.14   \n",
       "2            6.0            NaN                 1.00                     1.67   \n",
       "3            6.0           13.1                 0.84                     1.88   \n",
       "4            6.0           15.8                 1.03                     1.51   \n",
       "\n",
       "   ...  infratentorial_SAH  infratentorial_Petechiae  infratentorial_Edema  \\\n",
       "0  ...                   0                         0                     0   \n",
       "1  ...                  15                         0                     0   \n",
       "2  ...                   0                         0                     0   \n",
       "3  ...                   0                         0                     0   \n",
       "4  ...                   0                         0                     0   \n",
       "\n",
       "   brainstem_IPH  brainstem_SAH  brainstem_Petechiae  brainstem_Edema  SDH_y  \\\n",
       "0              0              0                    0                0   2476   \n",
       "1              0              0                    0                0     43   \n",
       "2              0              0                    0                0    312   \n",
       "3              0              0                    0                0     11   \n",
       "4              0              0                    0                0    796   \n",
       "\n",
       "     EDH   name  \n",
       "0    229  P0000  \n",
       "1      0  P0001  \n",
       "2  11685  P0002  \n",
       "3      0  P0003  \n",
       "4      0  P0004  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Verify if there are NaN values\n",
    "print(f\"Number of NaN values per column:\\n{X_prehosp_and_segmentation.isna().sum()}\")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "X_prehosp_and_segmentation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1ecfa3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name  mortality\n",
      "0  P0000          0\n",
      "1  P0001          0\n",
      "2  P0002          0\n",
      "3  P0003          0\n",
      "4  P0004          0\n",
      "Outcome events : 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bettik/PROJECTS/pr-gin5_aini/fehrdelt/FastDiag/data_preprocessing_outcomes.py:236: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col] = data[col].replace({'1': 1, '0': 0, 'nd': np.nan, '8 Upper Good Recovery (Upper GR)': np.nan}).astype(float)\n",
      "/bettik/PROJECTS/pr-gin5_aini/fehrdelt/FastDiag/data_preprocessing_outcomes.py:236: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col] = data[col].replace({'1': 1, '0': 0, 'nd': np.nan, '8 Upper Good Recovery (Upper GR)': np.nan}).astype(float)\n",
      "/bettik/PROJECTS/pr-gin5_aini/fehrdelt/FastDiag/data_preprocessing_outcomes.py:236: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col] = data[col].replace({'1': 1, '0': 0, 'nd': np.nan, '8 Upper Good Recovery (Upper GR)': np.nan}).astype(float)\n"
     ]
    }
   ],
   "source": [
    "X = X_prehosp_and_segmentation.copy()\n",
    "y = get_mortality_6m()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0b76bf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes with NaN in 'mortality': Index([], dtype='int64')\n",
      "Shape of y after cleaning: (566, 2)\n",
      "Shape of X after cleaning: (534, 35)\n",
      "Unique 'name' values in y: 562\n",
      "Unique 'name' values in X: 534\n",
      "Names in y but not in X: {'P0349', 'P0518', 'P0155', 'P0150', 'P0383', 'P0224', 'P0217', 'P0564', 'P0532', 'P0327', 'P0147', 'P0207', 'P0018', 'P0195', 'P0430', 'P0239', 'P0149', 'P0480', 'P0083', 'P0369', 'P0422', 'P0412', 'P0111', 'P0356', 'P0010', 'P0527', 'P0343', 'P0491'}\n",
      "Names in X but not in y: set()\n",
      "Shape of y after alignment: (536, 2)\n",
      "Shape of X after alignment: (534, 35)\n",
      "Number of duplicate names in y: 2\n",
      "Number of duplicate names in X: 0\n",
      "Shape of y after removing duplicates: (534, 2)\n",
      "Shape of X after removing duplicates: (534, 35)\n",
      "Are 'name' values aligned between y and X True\n"
     ]
    }
   ],
   "source": [
    "# Identify indexes where 'mortality' is NaN in y\n",
    "nan_indexes = y.loc[pd.isna(y[\"mortality\"]), :].index\n",
    "print(f\"Indexes with NaN in 'mortality': {nan_indexes}\")\n",
    "\n",
    "# Drop rows with NaN in y\n",
    "y = y.drop(index=nan_indexes)\n",
    "\n",
    "# Ensure 'name' is the index or used for alignment\n",
    "X = X[~X['name'].isin(y.loc[nan_indexes, 'name'])]\n",
    "\n",
    "# Verify the shapes after cleaning\n",
    "print(f\"Shape of y after cleaning: {y.shape}\")\n",
    "print(f\"Shape of X after cleaning: {X.shape}\")\n",
    "\n",
    "# Vérifiez les valeurs uniques de 'name' dans y\n",
    "print(\"Unique 'name' values in y:\", y['name'].nunique())\n",
    "\n",
    "# Vérifiez les valeurs uniques de 'name' dans X\n",
    "print(\"Unique 'name' values in X:\", X['name'].nunique())\n",
    "\n",
    "# Noms dans y mais pas dans X\n",
    "missing_in_X = set(y['name']) - set(X['name'])\n",
    "print(f\"Names in y but not in X: {missing_in_X}\")\n",
    "\n",
    "# Noms dans X mais pas dans y\n",
    "missing_in_y = set(X['name']) - set(y['name'])\n",
    "print(f\"Names in X but not in y: {missing_in_y}\")\n",
    "\n",
    "# Trouver les noms communs\n",
    "common_names = set(y['name']).intersection(set(X['name']))\n",
    "\n",
    "# Filtrer y et X pour ne garder que les noms communs\n",
    "y = y[y['name'].isin(common_names)]\n",
    "X = X[X['name'].isin(common_names)]\n",
    "\n",
    "# Vérifiez les dimensions après nettoyage\n",
    "print(f\"Shape of y after alignment: {y.shape}\")\n",
    "print(f\"Shape of X after alignment: {X.shape}\")\n",
    "\n",
    "# Check for duplicates in 'name' in y\n",
    "print(\"Number of duplicate names in y:\", y['name'].duplicated().sum())\n",
    "\n",
    "# Check for duplicates in 'name' in X\n",
    "print(\"Number of duplicate names in X:\", X['name'].duplicated().sum())\n",
    "\n",
    "# Remove duplicates from both DataFrames\n",
    "y = y.drop_duplicates(subset=['name'])\n",
    "X = X.drop_duplicates(subset=['name'])\n",
    "\n",
    "# Verify the shapes again\n",
    "print(f\"Shape of y after removing duplicates: {y.shape}\")\n",
    "print(f\"Shape of X after removing duplicates: {X.shape}\")\n",
    "\n",
    "# Check if 'name' values are the same in both DataFrames\n",
    "common_names = set(y['name']) == set(X['name'])\n",
    "print(f\"Are 'name' values aligned between y and X {common_names}\")\n",
    "\n",
    "# Drop the 'name' column from X_volumes_clinical_with_outcome\n",
    "X_features = X.drop(columns=['name'])\n",
    "\n",
    "# imputation with median \n",
    "X_features_imputed = X_features.fillna(X_features.median())\n",
    "\n",
    "# Drop the 'name' column from y (if it exists)\n",
    "y_outcome = y.drop(columns=['name'])\n",
    "\n",
    "# Ensure y_outcome is a 1D array\n",
    "y_outcome = y_outcome.values.ravel()  # Convert to 1D if using pandas DataFrame\n",
    "\n",
    "FOLDS = 5\n",
    "N_REPEATS = 3\n",
    "nb_total_samples = len(y_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c1b6d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8eb98e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoostingClassifier with hyperparameter gridsearch\n",
      "AUC (max): 0.94 +- 0.05\n",
      "F1 Score (max): 0.68 +- 0.11\n",
      "F2 Score (max): 0.72 +- 0.12\n",
      "Brier Score (min): 0.04 +- -0.01\n",
      "False negative: 2% +- 1\n",
      "False positive: 3% +- 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline_smote_under = Pipeline(steps=[('over', SMOTE()), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "#pipeline_smote_under = Pipeline(steps=[('over', SMOTENC(categorical_features=[\"fracas_du_bassin\", \"amputation\"])), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "\n",
    "\n",
    "inner_cv = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=5, random_state=1)\n",
    "\n",
    "p_grid = {\"model__learning_rate\": [0.01, 0.05, 0.08, 0.1, 0.2, 0.3, 0.5, 1], \"over__sampling_strategy\": [0.1, 0.2, 0.3], \"over__k_neighbors\":[3,5,8], \"under__sampling_strategy\":[0.3, 0.5, 0.7]}\n",
    "clf = GridSearchCV(estimator=pipeline_smote_under, param_grid=p_grid, scoring={'F2':ftwo_scorer}, refit='F2', cv=inner_cv)\n",
    "\n",
    "outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "nested_scores_smote_undersampling = cross_validate(clf, X_features_imputed, y_outcome, \n",
    "                                                scoring={'F2':ftwo_scorer, 'ROC_AUC':'roc_auc', 'Recall':'recall_macro', 'F1':'f1', 'Brier':\"neg_brier_score\", 'False_neg_scorer':false_neg_scorer, 'False_pos_scorer':false_pos_scorer}, \n",
    "                                                cv=outer_cv, n_jobs=-1, return_estimator=True, return_indices=True)\n",
    "\n",
    "print(\"HistGradientBoostingClassifier with hyperparameter gridsearch\")\n",
    "\n",
    "roc_auc_metric = np.mean(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "roc_auc_metric_std = np.std(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "print(f'AUC (max): {np.round(roc_auc_metric, 2)} +- {np.round(roc_auc_metric_std, 2)}')\n",
    "\n",
    "f1_score = np.mean(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "f1_score_std = np.std(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "print(f'F1 Score (max): {np.round(f1_score, 2)} +- {np.round(f1_score_std, 2)}')\n",
    "\n",
    "f2_score = np.mean(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "f2_score_std = np.std(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "print(f'F2 Score (max): {np.round(f2_score, 2)} +- {np.round(f2_score_std, 2)}')\n",
    "\n",
    "brier_score = -np.mean(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "brier_score_std = -np.std(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "print(f'Brier Score (min): {np.round(brier_score, 2)} +- {np.round(brier_score_std, 2)}')\n",
    "\n",
    "# test_False_neg_scorer returns the number of test false negatives -> to get a % we need to divide by the number of test samples*100\n",
    "false_neg_score = np.mean(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "false_neg_score_std = np.std(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "print(f'False negative: {int(np.round(false_neg_score, 0))}% +- {int(np.round(false_neg_score_std, 0))}')\n",
    "\n",
    "false_pos_score = np.mean(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "false_pos_score_std = np.std(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "print(f'False positive: {int(np.round(false_pos_score, 0))}% +- {int(np.round(false_pos_score_std, 0))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e5dce",
   "metadata": {},
   "source": [
    "#### Confidence intervals with test set bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c858796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_list = []\n",
    "\n",
    "for estimator in nested_scores_smote_undersampling[\"estimator\"]:\n",
    "    best_params_list.append(frozenset(estimator.best_params_.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "025a0bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final chosen hyperparameters: {'model__learning_rate': 0.2, 'under__sampling_strategy': 0.7, 'over__k_neighbors': 8, 'over__sampling_strategy': 0.3}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Convert dict to a hashable tuple and count occurrences\n",
    "most_common_params = Counter(best_params_list).most_common(1)[0][0]\n",
    "final_params = dict(most_common_params)  # Convert back to dict\n",
    "\n",
    "\n",
    "print(\"Final chosen hyperparameters:\", final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "537255a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('over', SMOTE(k_neighbors=8, sampling_strategy=0.3)), ('under', RandomUnderSampler(sampling_strategy=0.7)), ('model', HistGradientBoostingClassifier(learning_rate=0.2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "545b698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(pipeline, X_features_imputed, y_outcome, cv=20, method='predict_proba')[:,1]\n",
    "\n",
    "y_pred_binary = [1 if i>=0.5 else 0 for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dc6c94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, confusion_matrix, roc_auc_score, f1_score, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e72b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=12345)\n",
    "idx = np.arange(len(y_outcome))\n",
    "\n",
    "y_pred = np.asarray(y_pred)\n",
    "y_pred_binary = np.asarray(y_pred_binary)\n",
    "y = np.asarray(y_outcome)\n",
    "X_dropped = np.asarray(X_features_imputed)\n",
    "\n",
    "test_roc_auc = []\n",
    "test_f1 = []\n",
    "test_ftwos = []\n",
    "test_brier = []\n",
    "test_false_neg = []\n",
    "test_false_pos = []\n",
    "\n",
    "for i in range(200): # bootstrap with 200 rounds: random sampling with replacement of the predictions\n",
    "\n",
    "    pred_idx = rng.choice(idx, size=len(idx), replace=True)\n",
    "    \n",
    "    roc_auc_test_boot = roc_auc_score(y_score=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    f1_test_boot = f1_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx])\n",
    "    f2_test_boot = fbeta_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx], beta=2)\n",
    "    brier_test_boot = brier_score_loss(y_proba=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    false_neg_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[1,0]\n",
    "    false_pos_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[0,1]\n",
    "    \n",
    "    test_roc_auc.append(roc_auc_test_boot)\n",
    "    test_f1.append(f1_test_boot)\n",
    "    test_ftwos.append(f2_test_boot)\n",
    "    test_brier.append(brier_test_boot)\n",
    "    test_false_neg.append(false_neg_test_boot/len(idx)*100)\n",
    "    test_false_pos.append(false_pos_test_boot/len(idx)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "16013edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance\n",
      "\n",
      "ROC AUC:         0.94;   95% CI 0.87-0.99\n",
      "F1:              0.67;   95% CI 0.55-0.78\n",
      "F2:              0.70;   95% CI 0.57-0.82\n",
      "Brier loss:      0.04;   95% CI 0.02-0.05\n",
      "False negatives: 1.65%;  95% CI 0.75-2.81\n",
      "False negatives: 2.67%; 95% CI 1.31-3.94\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification performance\\n\")\n",
    "\n",
    "bootstrap_roc_auc_test_mean = np.mean(test_roc_auc)\n",
    "ci_lower = np.percentile(test_roc_auc, 2.5)     # 2.5 percentile (alpha=0.025)\n",
    "ci_upper = np.percentile(test_roc_auc, 97.5)\n",
    "print(f\"ROC AUC:         {bootstrap_roc_auc_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f1_test_mean = np.mean(test_f1)\n",
    "ci_lower = np.percentile(test_f1, 2.5)\n",
    "ci_upper = np.percentile(test_f1, 97.5)\n",
    "print(f\"F1:              {bootstrap_f1_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f2_test_mean = np.mean(test_ftwos)\n",
    "ci_lower = np.percentile(test_ftwos, 2.5)\n",
    "ci_upper = np.percentile(test_ftwos, 97.5)\n",
    "print(f\"F2:              {bootstrap_f2_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_brier_test_mean = np.mean(test_brier)\n",
    "ci_lower = np.percentile(test_brier, 2.5)\n",
    "ci_upper = np.percentile(test_brier, 97.5)\n",
    "print(f\"Brier loss:      {bootstrap_brier_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_neg_test_mean = np.mean(test_false_neg)\n",
    "ci_lower = np.percentile(test_false_neg, 2.5)\n",
    "ci_upper = np.percentile(test_false_neg, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_neg_test_mean:.2f}%;  95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_pos_test_mean = np.mean(test_false_pos)\n",
    "ci_lower = np.percentile(test_false_pos, 2.5)\n",
    "ci_upper = np.percentile(test_false_pos, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_pos_test_mean:.2f}%; 95% CI {ci_lower:.2f}-{ci_upper:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbabbe4b-1a9b-48a8-822a-6630894899e1",
   "metadata": {},
   "source": [
    "### Gradient boosting with all DCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab607165-596f-4a88-840c-425dcd331ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run preproc outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f881797-c414-45a7-b86d-e94c2b413422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAS DCA</th>\n",
       "      <th>PAD DCA</th>\n",
       "      <th>FC  DCA</th>\n",
       "      <th>Shock index DCA</th>\n",
       "      <th>Shock Index inversé.1</th>\n",
       "      <th>Shock index diastolique.1</th>\n",
       "      <th>GCS DCA</th>\n",
       "      <th>GCS (M) DCA</th>\n",
       "      <th>Température DCA</th>\n",
       "      <th>Hémocue DCA</th>\n",
       "      <th>Dextro DCA (mmol/l)</th>\n",
       "      <th>DTC Vd</th>\n",
       "      <th>DTC IP</th>\n",
       "      <th>Osmothérapie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>87</td>\n",
       "      <td>132</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.52</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>14.3</td>\n",
       "      <td>nd</td>\n",
       "      <td>nd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>35.2</td>\n",
       "      <td>14</td>\n",
       "      <td>5.9</td>\n",
       "      <td>46</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>nd</td>\n",
       "      <td>38.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>55</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.83</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>nd</td>\n",
       "      <td>nd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PAS DCA PAD DCA FC  DCA Shock index DCA Shock Index inversé.1  \\\n",
       "0     120      87     132             1.1                  0.91   \n",
       "1     110      60      60            0.55                  1.83   \n",
       "2     110      50     100            0.91                   1.1   \n",
       "3     120      90     120               1                     1   \n",
       "4     120      60     110            0.92                  1.09   \n",
       "\n",
       "  Shock index diastolique.1 GCS DCA GCS (M) DCA Température DCA Hémocue DCA  \\\n",
       "0                      1.52      15           6            37.2        13.7   \n",
       "1                         1      15           6            35.2          14   \n",
       "2                         2      13          nd            38.2        12.7   \n",
       "3                      1.33      15           6            37.8        12.8   \n",
       "4                      1.83      15           6            37.1        15.6   \n",
       "\n",
       "  Dextro DCA (mmol/l) DTC Vd DTC IP Osmothérapie  \n",
       "0                14.3     nd     nd            0  \n",
       "1                 5.9     46    0.8            0  \n",
       "2                 6.4     55    1.3            0  \n",
       "3                 6.8     32    0.9            0  \n",
       "4                 9.4     nd     nd            0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select columns\n",
    "X_dca = data_full.iloc[:, 35:49]\n",
    "\n",
    "# Convert all columns to numeric, replacing non-numeric values and empty strings with NaN\n",
    "#X_dca = X_dca.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "X_dca.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6045136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values per column:\n",
      "PAS DCA                       12\n",
      "PAD DCA                       12\n",
      "FC  DCA                       13\n",
      "Shock index DCA                0\n",
      "Shock Index inversé.1          0\n",
      "Shock index diastolique.1      0\n",
      "GCS DCA                       14\n",
      "GCS (M) DCA                   20\n",
      "Température DCA               20\n",
      "Hémocue DCA                   25\n",
      "Dextro DCA (mmol/l)           53\n",
      "DTC Vd                        16\n",
      "DTC IP                       329\n",
      "Osmothérapie                  11\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAS DCA</th>\n",
       "      <th>PAD DCA</th>\n",
       "      <th>FC  DCA</th>\n",
       "      <th>Shock index DCA</th>\n",
       "      <th>Shock Index inversé.1</th>\n",
       "      <th>Shock index diastolique.1</th>\n",
       "      <th>GCS DCA</th>\n",
       "      <th>GCS (M) DCA</th>\n",
       "      <th>Température DCA</th>\n",
       "      <th>Hémocue DCA</th>\n",
       "      <th>Dextro DCA (mmol/l)</th>\n",
       "      <th>DTC Vd</th>\n",
       "      <th>DTC IP</th>\n",
       "      <th>Osmothérapie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>87</td>\n",
       "      <td>132</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.52</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>14.3</td>\n",
       "      <td>nd</td>\n",
       "      <td>nd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>35.2</td>\n",
       "      <td>14</td>\n",
       "      <td>5.9</td>\n",
       "      <td>46</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>nd</td>\n",
       "      <td>38.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>55</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.83</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>nd</td>\n",
       "      <td>nd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PAS DCA PAD DCA FC  DCA Shock index DCA Shock Index inversé.1  \\\n",
       "0     120      87     132             1.1                  0.91   \n",
       "1     110      60      60            0.55                  1.83   \n",
       "2     110      50     100            0.91                   1.1   \n",
       "3     120      90     120               1                     1   \n",
       "4     120      60     110            0.92                  1.09   \n",
       "\n",
       "  Shock index diastolique.1 GCS DCA GCS (M) DCA Température DCA Hémocue DCA  \\\n",
       "0                      1.52      15           6            37.2        13.7   \n",
       "1                         1      15           6            35.2          14   \n",
       "2                         2      13          nd            38.2        12.7   \n",
       "3                      1.33      15           6            37.8        12.8   \n",
       "4                      1.83      15           6            37.1        15.6   \n",
       "\n",
       "  Dextro DCA (mmol/l) DTC Vd DTC IP Osmothérapie  \n",
       "0                14.3     nd     nd            0  \n",
       "1                 5.9     46    0.8            0  \n",
       "2                 6.4     55    1.3            0  \n",
       "3                 6.8     32    0.9            0  \n",
       "4                 9.4     nd     nd            0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Verify if there are NaN values\n",
    "print(f\"Number of NaN values per column:\\n{X_dca.isna().sum()}\")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "X_dca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a576b044-2342-47a3-a06b-04c56ce4b257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAS DCA</th>\n",
       "      <th>PAD DCA</th>\n",
       "      <th>FC  DCA</th>\n",
       "      <th>Shock index DCA</th>\n",
       "      <th>Shock Index inversé.1</th>\n",
       "      <th>Shock index diastolique.1</th>\n",
       "      <th>GCS DCA</th>\n",
       "      <th>GCS (M) DCA</th>\n",
       "      <th>Température DCA</th>\n",
       "      <th>Hémocue DCA</th>\n",
       "      <th>Dextro DCA (mmol/l)</th>\n",
       "      <th>DTC Vd</th>\n",
       "      <th>DTC IP</th>\n",
       "      <th>Osmothérapie</th>\n",
       "      <th>dtc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>87</td>\n",
       "      <td>132</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.52</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>14.3</td>\n",
       "      <td>nd</td>\n",
       "      <td>nd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>35.2</td>\n",
       "      <td>14</td>\n",
       "      <td>5.9</td>\n",
       "      <td>46</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>nd</td>\n",
       "      <td>38.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>55</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.83</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>nd</td>\n",
       "      <td>nd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PAS DCA PAD DCA FC  DCA Shock index DCA Shock Index inversé.1  \\\n",
       "0     120      87     132             1.1                  0.91   \n",
       "1     110      60      60            0.55                  1.83   \n",
       "2     110      50     100            0.91                   1.1   \n",
       "3     120      90     120               1                     1   \n",
       "4     120      60     110            0.92                  1.09   \n",
       "\n",
       "  Shock index diastolique.1 GCS DCA GCS (M) DCA Température DCA Hémocue DCA  \\\n",
       "0                      1.52      15           6            37.2        13.7   \n",
       "1                         1      15           6            35.2          14   \n",
       "2                         2      13          nd            38.2        12.7   \n",
       "3                      1.33      15           6            37.8        12.8   \n",
       "4                      1.83      15           6            37.1        15.6   \n",
       "\n",
       "  Dextro DCA (mmol/l) DTC Vd DTC IP Osmothérapie  dtc  \n",
       "0                14.3     nd     nd            0  0.0  \n",
       "1                 5.9     46    0.8            0  0.0  \n",
       "2                 6.4     55    1.3            0  1.0  \n",
       "3                 6.8     32    0.9            0  0.0  \n",
       "4                 9.4     nd     nd            0  0.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the conditions for dtc\n",
    "def calculate_dtc(row):\n",
    "    # Condition for dtc = NA\n",
    "    if ('nr' in [row['DTC Vd'], row['DTC IP']] or\n",
    "        'non réalisé' in [row['DTC Vd'], row['DTC IP']]):\n",
    "        return np.nan\n",
    "    # Condition for dtc = 1\n",
    "    if (row['DTC Vd'] == 'Pathologique' or row['DTC IP'] == 'Pathologique' or\n",
    "        (is_numeric(row['DTC Vd']) and float(row['DTC Vd']) < 30) or\n",
    "        (is_numeric(row['DTC IP']) and float(row['DTC IP']) > 1.2)):\n",
    "        return 1\n",
    "    # Default case for dtc = 0\n",
    "    return 0\n",
    "\n",
    "# Helper function to check if a value is numeric\n",
    "def is_numeric(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "# Apply the function row-wise to create the new column\n",
    "X_dca['dtc'] = X_dca.apply(calculate_dtc, axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "X_dca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e7766877-9380-439e-b510-2fb0c92235a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values per column:\n",
      "PAS DCA                       14\n",
      "PAD DCA                       14\n",
      "FC  DCA                       17\n",
      "Shock index DCA               20\n",
      "Shock Index inversé.1         20\n",
      "Shock index diastolique.1     20\n",
      "GCS DCA                       30\n",
      "GCS (M) DCA                   33\n",
      "Température DCA              402\n",
      "Hémocue DCA                   37\n",
      "Dextro DCA (mmol/l)           75\n",
      "DTC Vd                       453\n",
      "DTC IP                       452\n",
      "Osmothérapie                 395\n",
      "dtc                          163\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert all columns to numeric, replacing non-numeric values and empty strings with NaN\n",
    "X_dca = X_dca.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "X_dca.head()\n",
    "\n",
    "# Verify if there are NaN values\n",
    "print(f\"Number of NaN values per column:\\n{X_dca.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a36e772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name  mortality\n",
      "0  P0000          0\n",
      "1  P0001          0\n",
      "2  P0002          0\n",
      "3  P0003          0\n",
      "4  P0004          0\n",
      "Outcome events : 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bettik/PROJECTS/pr-gin5_aini/fehrdelt/FastDiag/data_preprocessing_outcomes.py:236: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col] = data[col].replace({'1': 1, '0': 0, 'nd': np.nan, '8 Upper Good Recovery (Upper GR)': np.nan}).astype(float)\n",
      "/bettik/PROJECTS/pr-gin5_aini/fehrdelt/FastDiag/data_preprocessing_outcomes.py:236: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col] = data[col].replace({'1': 1, '0': 0, 'nd': np.nan, '8 Upper Good Recovery (Upper GR)': np.nan}).astype(float)\n",
      "/bettik/PROJECTS/pr-gin5_aini/fehrdelt/FastDiag/data_preprocessing_outcomes.py:236: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col] = data[col].replace({'1': 1, '0': 0, 'nd': np.nan, '8 Upper Good Recovery (Upper GR)': np.nan}).astype(float)\n"
     ]
    }
   ],
   "source": [
    "# Include column name\n",
    "X_dca = pd.concat([X_dca, data_full.iloc[:, 2]], axis=1)\n",
    "X = X_dca.copy()\n",
    "y = get_mortality_6m()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da6d88fc-8c5a-44fb-b5a2-239477df9b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes with NaN in 'mortality': Index([], dtype='int64')\n",
      "Shape of y after cleaning: (534, 2)\n",
      "Shape of X after cleaning: (534, 16)\n",
      "Unique 'name' values in y: 534\n",
      "Unique 'name' values in X: 534\n",
      "Names in y but not in X: set()\n",
      "Names in X but not in y: set()\n",
      "Shape of y after alignment: (534, 2)\n",
      "Shape of X after alignment: (534, 16)\n",
      "Number of duplicate names in y: 0\n",
      "Number of duplicate names in X: 0\n",
      "Shape of y after removing duplicates: (534, 2)\n",
      "Shape of X after removing duplicates: (534, 16)\n",
      "Are 'name' values aligned between y and X True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Identify indexes where 'mortality' is NaN in y\n",
    "nan_indexes = y.loc[pd.isna(y[\"mortality\"]), :].index\n",
    "print(f\"Indexes with NaN in 'mortality': {nan_indexes}\")\n",
    "\n",
    "# Drop rows with NaN in y\n",
    "y = y.drop(index=nan_indexes)\n",
    "\n",
    "# Ensure 'name' is the index or used for alignment\n",
    "X = X[~X['name'].isin(y.loc[nan_indexes, 'name'])]\n",
    "\n",
    "# Verify the shapes after cleaning\n",
    "print(f\"Shape of y after cleaning: {y.shape}\")\n",
    "print(f\"Shape of X after cleaning: {X.shape}\")\n",
    "\n",
    "# Vérifiez les valeurs uniques de 'name' dans y\n",
    "print(\"Unique 'name' values in y:\", y['name'].nunique())\n",
    "\n",
    "# Vérifiez les valeurs uniques de 'name' dans X\n",
    "print(\"Unique 'name' values in X:\", X['name'].nunique())\n",
    "\n",
    "# Noms dans y mais pas dans X\n",
    "missing_in_X = set(y['name']) - set(X['name'])\n",
    "print(f\"Names in y but not in X: {missing_in_X}\")\n",
    "\n",
    "# Noms dans X mais pas dans y\n",
    "missing_in_y = set(X['name']) - set(y['name'])\n",
    "print(f\"Names in X but not in y: {missing_in_y}\")\n",
    "\n",
    "# Trouver les noms communs\n",
    "common_names = set(y['name']).intersection(set(X['name']))\n",
    "\n",
    "# Filtrer y et X pour ne garder que les noms communs\n",
    "y = y[y['name'].isin(common_names)]\n",
    "X = X[X['name'].isin(common_names)]\n",
    "\n",
    "# Vérifiez les dimensions après nettoyage\n",
    "print(f\"Shape of y after alignment: {y.shape}\")\n",
    "print(f\"Shape of X after alignment: {X.shape}\")\n",
    "\n",
    "# Check for duplicates in 'name' in y\n",
    "print(\"Number of duplicate names in y:\", y['name'].duplicated().sum())\n",
    "\n",
    "# Check for duplicates in 'name' in X\n",
    "print(\"Number of duplicate names in X:\", X['name'].duplicated().sum())\n",
    "\n",
    "# Remove duplicates from both DataFrames\n",
    "y = y.drop_duplicates(subset=['name'])\n",
    "X = X.drop_duplicates(subset=['name'])\n",
    "\n",
    "# Verify the shapes again\n",
    "print(f\"Shape of y after removing duplicates: {y.shape}\")\n",
    "print(f\"Shape of X after removing duplicates: {X.shape}\")\n",
    "\n",
    "# Check if 'name' values are the same in both DataFrames\n",
    "common_names = set(y['name']) == set(X['name'])\n",
    "print(f\"Are 'name' values aligned between y and X {common_names}\")\n",
    "\n",
    "# Trier y et X par la colonne 'name'\n",
    "y = y.sort_values(by='name').reset_index(drop=True)\n",
    "X = X.sort_values(by='name').reset_index(drop=True)\n",
    "\n",
    "# Vérifier si les noms sont alignés\n",
    "print((y['name'].values == X['name'].values).all())\n",
    "\n",
    "# Drop the 'name' column from X\n",
    "#X_features = X.drop(columns=['name', 'mortalité J7'])\n",
    "X_features = X.drop(columns=['name'])\n",
    "\n",
    "# imputation with median \n",
    "X_features_imputed = X_features.fillna(X_features.median())\n",
    "\n",
    "# Drop the 'name' column from y (if it exists)\n",
    "y_outcome = y.drop(columns=['name'])\n",
    "\n",
    "# Ensure y_outcome is a 1D array\n",
    "y_outcome = y_outcome.values.ravel()  # Convert to 1D if using pandas DataFrame\n",
    "\n",
    "FOLDS = 5\n",
    "N_REPEATS = 3\n",
    "nb_total_samples = len(y_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac10ad2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAS DCA</th>\n",
       "      <th>PAD DCA</th>\n",
       "      <th>FC  DCA</th>\n",
       "      <th>Shock index DCA</th>\n",
       "      <th>Shock Index inversé.1</th>\n",
       "      <th>Shock index diastolique.1</th>\n",
       "      <th>GCS DCA</th>\n",
       "      <th>GCS (M) DCA</th>\n",
       "      <th>Température DCA</th>\n",
       "      <th>Hémocue DCA</th>\n",
       "      <th>Dextro DCA (mmol/l)</th>\n",
       "      <th>DTC Vd</th>\n",
       "      <th>DTC IP</th>\n",
       "      <th>Osmothérapie</th>\n",
       "      <th>dtc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.52</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>14.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.83</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PAS DCA  PAD DCA  FC  DCA  Shock index DCA  Shock Index inversé.1  \\\n",
       "0    120.0     87.0    132.0             1.10                   0.91   \n",
       "1    110.0     60.0     60.0             0.55                   1.83   \n",
       "2    110.0     50.0    100.0             0.91                   1.10   \n",
       "3    120.0     90.0    120.0             1.00                   1.00   \n",
       "4    120.0     60.0    110.0             0.92                   1.09   \n",
       "\n",
       "   Shock index diastolique.1  GCS DCA  GCS (M) DCA  Température DCA  \\\n",
       "0                       1.52     15.0          6.0             37.2   \n",
       "1                       1.00     15.0          6.0             35.2   \n",
       "2                       2.00     13.0          NaN             38.2   \n",
       "3                       1.33     15.0          6.0             37.8   \n",
       "4                       1.83     15.0          6.0             37.1   \n",
       "\n",
       "   Hémocue DCA  Dextro DCA (mmol/l)  DTC Vd  DTC IP  Osmothérapie  dtc  \n",
       "0         13.7                 14.3     NaN     NaN           0.0  0.0  \n",
       "1         14.0                  5.9    46.0     0.8           0.0  0.0  \n",
       "2         12.7                  6.4    55.0     1.3           0.0  1.0  \n",
       "3         12.8                  6.8    32.0     0.9           0.0  0.0  \n",
       "4         15.6                  9.4     NaN     NaN           0.0  0.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4848be20-adbc-40dd-9140-988736609fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoostingClassifier with hyperparameter gridsearch\n",
      "AUC (max): 0.88 +- 0.07\n",
      "F1 Score (max): 0.45 +- 0.1\n",
      "F2 Score (max): 0.56 +- 0.12\n",
      "Brier Score (min): 0.09 +- -0.01\n",
      "False negative: 2% +- 1\n",
      "False positive: 9% +- 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline_smote_under = Pipeline(steps=[('over', SMOTE()), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "#pipeline_smote_under = Pipeline(steps=[('over', SMOTENC(categorical_features=[\"fracas_du_bassin\", \"amputation\"])), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "\n",
    "\n",
    "inner_cv = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=5, random_state=1)\n",
    "\n",
    "p_grid = {\"model__learning_rate\": [0.01, 0.05, 0.08, 0.1, 0.2, 0.3, 0.5, 1], \"over__sampling_strategy\": [0.1, 0.2, 0.3], \"over__k_neighbors\":[3,5,8], \"under__sampling_strategy\":[0.3, 0.5, 0.7]}\n",
    "clf = GridSearchCV(estimator=pipeline_smote_under, param_grid=p_grid, scoring={'F2':ftwo_scorer}, refit='F2', cv=inner_cv)\n",
    "\n",
    "outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "nested_scores_smote_undersampling = cross_validate(clf, X_features_imputed, y_outcome, \n",
    "                                                scoring={'F2':ftwo_scorer, 'ROC_AUC':'roc_auc', 'Recall':'recall_macro', 'F1':'f1', 'Brier':\"neg_brier_score\", 'False_neg_scorer':false_neg_scorer, 'False_pos_scorer':false_pos_scorer}, \n",
    "                                                cv=outer_cv, n_jobs=-1, return_estimator=True, return_indices=True)\n",
    "\n",
    "print(\"HistGradientBoostingClassifier with hyperparameter gridsearch\")\n",
    "\n",
    "roc_auc_metric = np.mean(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "roc_auc_metric_std = np.std(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "print(f'AUC (max): {np.round(roc_auc_metric, 2)} +- {np.round(roc_auc_metric_std, 2)}')\n",
    "\n",
    "f1_score = np.mean(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "f1_score_std = np.std(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "print(f'F1 Score (max): {np.round(f1_score, 2)} +- {np.round(f1_score_std, 2)}')\n",
    "\n",
    "f2_score = np.mean(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "f2_score_std = np.std(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "print(f'F2 Score (max): {np.round(f2_score, 2)} +- {np.round(f2_score_std, 2)}')\n",
    "\n",
    "brier_score = -np.mean(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "brier_score_std = -np.std(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "print(f'Brier Score (min): {np.round(brier_score, 2)} +- {np.round(brier_score_std, 2)}')\n",
    "\n",
    "# test_False_neg_scorer returns the number of test false negatives -> to get a % we need to divide by the number of test samples*100\n",
    "false_neg_score = np.mean(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "false_neg_score_std = np.std(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "print(f'False negative: {int(np.round(false_neg_score, 0))}% +- {int(np.round(false_neg_score_std, 0))}')\n",
    "\n",
    "false_pos_score = np.mean(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "false_pos_score_std = np.std(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "print(f'False positive: {int(np.round(false_pos_score, 0))}% +- {int(np.round(false_pos_score_std, 0))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700751fc",
   "metadata": {},
   "source": [
    "#### Confidence intervals with test set bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9dabd807",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_list = []\n",
    "\n",
    "for estimator in nested_scores_smote_undersampling[\"estimator\"]:\n",
    "    best_params_list.append(frozenset(estimator.best_params_.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f75d3f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final chosen hyperparameters: {'model__learning_rate': 0.01, 'under__sampling_strategy': 0.7, 'over__k_neighbors': 3, 'over__sampling_strategy': 0.2}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Convert dict to a hashable tuple and count occurrences\n",
    "most_common_params = Counter(best_params_list).most_common(1)[0][0]\n",
    "final_params = dict(most_common_params)  # Convert back to dict\n",
    "\n",
    "\n",
    "print(\"Final chosen hyperparameters:\", final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eaa41af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('over', SMOTE(k_neighbors=3, sampling_strategy=0.2)), ('under', RandomUnderSampler(sampling_strategy=0.7)), ('model', HistGradientBoostingClassifier(learning_rate=0.01))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8fd63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(pipeline, X_features_imputed, y_outcome, cv=20, method='predict_proba')[:,1]\n",
    "\n",
    "y_pred_binary = [1 if i>=0.5 else 0 for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8687d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, confusion_matrix, roc_auc_score, f1_score, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3cfa309",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=12345)\n",
    "idx = np.arange(len(y_outcome))\n",
    "\n",
    "y_pred = np.asarray(y_pred)\n",
    "y_pred_binary = np.asarray(y_pred_binary)\n",
    "y = np.asarray(y_outcome)\n",
    "X_dropped = np.asarray(X_features_imputed)\n",
    "\n",
    "test_roc_auc = []\n",
    "test_f1 = []\n",
    "test_ftwos = []\n",
    "test_brier = []\n",
    "test_false_neg = []\n",
    "test_false_pos = []\n",
    "\n",
    "for i in range(200): # bootstrap with 200 rounds: random sampling with replacement of the predictions\n",
    "\n",
    "    pred_idx = rng.choice(idx, size=len(idx), replace=True)\n",
    "    \n",
    "    roc_auc_test_boot = roc_auc_score(y_score=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    f1_test_boot = f1_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx])\n",
    "    f2_test_boot = fbeta_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx], beta=2)\n",
    "    brier_test_boot = brier_score_loss(y_proba=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    false_neg_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[1,0]\n",
    "    false_pos_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[0,1]\n",
    "    \n",
    "    test_roc_auc.append(roc_auc_test_boot)\n",
    "    test_f1.append(f1_test_boot)\n",
    "    test_ftwos.append(f2_test_boot)\n",
    "    test_brier.append(brier_test_boot)\n",
    "    test_false_neg.append(false_neg_test_boot/len(idx)*100)\n",
    "    test_false_pos.append(false_pos_test_boot/len(idx)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d97752f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance\n",
      "\n",
      "ROC AUC:         0.87;   95% CI 0.81-0.94\n",
      "F1:              0.46;   95% CI 0.33-0.57\n",
      "F2:              0.58;   95% CI 0.44-0.69\n",
      "Brier loss:      0.09;   95% CI 0.08-0.10\n",
      "False negatives: 1.84%;  95% CI 0.74-3.18\n",
      "False negatives: 8.16%; 95% CI 5.99-10.49\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification performance\\n\")\n",
    "\n",
    "bootstrap_roc_auc_test_mean = np.mean(test_roc_auc)\n",
    "ci_lower = np.percentile(test_roc_auc, 2.5)     # 2.5 percentile (alpha=0.025)\n",
    "ci_upper = np.percentile(test_roc_auc, 97.5)\n",
    "print(f\"ROC AUC:         {bootstrap_roc_auc_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f1_test_mean = np.mean(test_f1)\n",
    "ci_lower = np.percentile(test_f1, 2.5)\n",
    "ci_upper = np.percentile(test_f1, 97.5)\n",
    "print(f\"F1:              {bootstrap_f1_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f2_test_mean = np.mean(test_ftwos)\n",
    "ci_lower = np.percentile(test_ftwos, 2.5)\n",
    "ci_upper = np.percentile(test_ftwos, 97.5)\n",
    "print(f\"F2:              {bootstrap_f2_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_brier_test_mean = np.mean(test_brier)\n",
    "ci_lower = np.percentile(test_brier, 2.5)\n",
    "ci_upper = np.percentile(test_brier, 97.5)\n",
    "print(f\"Brier loss:      {bootstrap_brier_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_neg_test_mean = np.mean(test_false_neg)\n",
    "ci_lower = np.percentile(test_false_neg, 2.5)\n",
    "ci_upper = np.percentile(test_false_neg, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_neg_test_mean:.2f}%;  95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_pos_test_mean = np.mean(test_false_pos)\n",
    "ci_lower = np.percentile(test_false_pos, 2.5)\n",
    "ci_upper = np.percentile(test_false_pos, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_pos_test_mean:.2f}%; 95% CI {ci_lower:.2f}-{ci_upper:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40882def",
   "metadata": {},
   "source": [
    "### Gradient boosting with all DCA + segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "547ad95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run preproc outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f0322828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAS DCA</th>\n",
       "      <th>PAD DCA</th>\n",
       "      <th>FC  DCA</th>\n",
       "      <th>Shock index DCA</th>\n",
       "      <th>Shock Index inversé.1</th>\n",
       "      <th>Shock index diastolique.1</th>\n",
       "      <th>GCS DCA</th>\n",
       "      <th>GCS (M) DCA</th>\n",
       "      <th>Température DCA</th>\n",
       "      <th>Hémocue DCA</th>\n",
       "      <th>...</th>\n",
       "      <th>infratentorial_IPH</th>\n",
       "      <th>infratentorial_SAH</th>\n",
       "      <th>infratentorial_Petechiae</th>\n",
       "      <th>infratentorial_Edema</th>\n",
       "      <th>brainstem_IPH</th>\n",
       "      <th>brainstem_SAH</th>\n",
       "      <th>brainstem_Petechiae</th>\n",
       "      <th>brainstem_Edema</th>\n",
       "      <th>SDH_y</th>\n",
       "      <th>EDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>87</td>\n",
       "      <td>132</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.52</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2476</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>35.2</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>nd</td>\n",
       "      <td>38.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>11685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.83</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PAS DCA PAD DCA FC  DCA Shock index DCA Shock Index inversé.1  \\\n",
       "0     120      87     132             1.1                  0.91   \n",
       "1     110      60      60            0.55                  1.83   \n",
       "2     110      50     100            0.91                   1.1   \n",
       "3     120      90     120               1                     1   \n",
       "4     120      60     110            0.92                  1.09   \n",
       "\n",
       "  Shock index diastolique.1 GCS DCA GCS (M) DCA Température DCA Hémocue DCA  \\\n",
       "0                      1.52      15           6            37.2        13.7   \n",
       "1                         1      15           6            35.2          14   \n",
       "2                         2      13          nd            38.2        12.7   \n",
       "3                      1.33      15           6            37.8        12.8   \n",
       "4                      1.83      15           6            37.1        15.6   \n",
       "\n",
       "   ... infratentorial_IPH infratentorial_SAH infratentorial_Petechiae  \\\n",
       "0  ...                  0                  0                        0   \n",
       "1  ...                  0                 15                        0   \n",
       "2  ...                  0                  0                        0   \n",
       "3  ...                  0                  0                        0   \n",
       "4  ...                  0                  0                        0   \n",
       "\n",
       "  infratentorial_Edema  brainstem_IPH  brainstem_SAH  brainstem_Petechiae  \\\n",
       "0                    0              0              0                    0   \n",
       "1                    0              0              0                    0   \n",
       "2                    0              0              0                    0   \n",
       "3                    0              0              0                    0   \n",
       "4                    0              0              0                    0   \n",
       "\n",
       "   brainstem_Edema  SDH_y    EDH  \n",
       "0                0   2476    229  \n",
       "1                0     43      0  \n",
       "2                0    312  11685  \n",
       "3                0     11      0  \n",
       "4                0    796      0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select columns (DCA)\n",
    "X_dca_and_segmentation = data_full.iloc[:, 35:49] # add 92:\n",
    "\n",
    "# Add segmentation columns\n",
    "X_dca_and_segmentation = pd.concat([X_dca_and_segmentation, data_full.iloc[:, 101:115]], axis=1)\n",
    "\n",
    "\n",
    "# Convert all columns to numeric, replacing non-numeric values and empty strings with NaN\n",
    "#X_dca = X_dca.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "X_dca_and_segmentation.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a54e46cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values per column:\n",
      "PAS DCA                       12\n",
      "PAD DCA                       12\n",
      "FC  DCA                       13\n",
      "Shock index DCA                0\n",
      "Shock Index inversé.1          0\n",
      "Shock index diastolique.1      0\n",
      "GCS DCA                       14\n",
      "GCS (M) DCA                   20\n",
      "Température DCA               20\n",
      "Hémocue DCA                   25\n",
      "Dextro DCA (mmol/l)           53\n",
      "DTC Vd                        16\n",
      "DTC IP                       329\n",
      "Osmothérapie                  11\n",
      "supratentorial_IPH             0\n",
      "supratentorial_SAH             0\n",
      "supratentorial_Petechiae       0\n",
      "supratentorial_Edema           0\n",
      "infratentorial_IPH             0\n",
      "infratentorial_SAH             0\n",
      "infratentorial_Petechiae       0\n",
      "infratentorial_Edema           0\n",
      "brainstem_IPH                  0\n",
      "brainstem_SAH                  0\n",
      "brainstem_Petechiae            0\n",
      "brainstem_Edema                0\n",
      "SDH_y                          0\n",
      "EDH                            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAS DCA</th>\n",
       "      <th>PAD DCA</th>\n",
       "      <th>FC  DCA</th>\n",
       "      <th>Shock index DCA</th>\n",
       "      <th>Shock Index inversé.1</th>\n",
       "      <th>Shock index diastolique.1</th>\n",
       "      <th>GCS DCA</th>\n",
       "      <th>GCS (M) DCA</th>\n",
       "      <th>Température DCA</th>\n",
       "      <th>Hémocue DCA</th>\n",
       "      <th>...</th>\n",
       "      <th>infratentorial_IPH</th>\n",
       "      <th>infratentorial_SAH</th>\n",
       "      <th>infratentorial_Petechiae</th>\n",
       "      <th>infratentorial_Edema</th>\n",
       "      <th>brainstem_IPH</th>\n",
       "      <th>brainstem_SAH</th>\n",
       "      <th>brainstem_Petechiae</th>\n",
       "      <th>brainstem_Edema</th>\n",
       "      <th>SDH_y</th>\n",
       "      <th>EDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>87</td>\n",
       "      <td>132</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.52</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2476</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>35.2</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>nd</td>\n",
       "      <td>38.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>11685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.83</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PAS DCA PAD DCA FC  DCA Shock index DCA Shock Index inversé.1  \\\n",
       "0     120      87     132             1.1                  0.91   \n",
       "1     110      60      60            0.55                  1.83   \n",
       "2     110      50     100            0.91                   1.1   \n",
       "3     120      90     120               1                     1   \n",
       "4     120      60     110            0.92                  1.09   \n",
       "\n",
       "  Shock index diastolique.1 GCS DCA GCS (M) DCA Température DCA Hémocue DCA  \\\n",
       "0                      1.52      15           6            37.2        13.7   \n",
       "1                         1      15           6            35.2          14   \n",
       "2                         2      13          nd            38.2        12.7   \n",
       "3                      1.33      15           6            37.8        12.8   \n",
       "4                      1.83      15           6            37.1        15.6   \n",
       "\n",
       "   ... infratentorial_IPH infratentorial_SAH infratentorial_Petechiae  \\\n",
       "0  ...                  0                  0                        0   \n",
       "1  ...                  0                 15                        0   \n",
       "2  ...                  0                  0                        0   \n",
       "3  ...                  0                  0                        0   \n",
       "4  ...                  0                  0                        0   \n",
       "\n",
       "  infratentorial_Edema  brainstem_IPH  brainstem_SAH  brainstem_Petechiae  \\\n",
       "0                    0              0              0                    0   \n",
       "1                    0              0              0                    0   \n",
       "2                    0              0              0                    0   \n",
       "3                    0              0              0                    0   \n",
       "4                    0              0              0                    0   \n",
       "\n",
       "   brainstem_Edema  SDH_y    EDH  \n",
       "0                0   2476    229  \n",
       "1                0     43      0  \n",
       "2                0    312  11685  \n",
       "3                0     11      0  \n",
       "4                0    796      0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Verify if there are NaN values\n",
    "print(f\"Number of NaN values per column:\\n{X_dca_and_segmentation.isna().sum()}\")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "X_dca_and_segmentation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d4ec7e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAS DCA</th>\n",
       "      <th>PAD DCA</th>\n",
       "      <th>FC  DCA</th>\n",
       "      <th>Shock index DCA</th>\n",
       "      <th>Shock Index inversé.1</th>\n",
       "      <th>Shock index diastolique.1</th>\n",
       "      <th>GCS DCA</th>\n",
       "      <th>GCS (M) DCA</th>\n",
       "      <th>Température DCA</th>\n",
       "      <th>Hémocue DCA</th>\n",
       "      <th>...</th>\n",
       "      <th>infratentorial_SAH</th>\n",
       "      <th>infratentorial_Petechiae</th>\n",
       "      <th>infratentorial_Edema</th>\n",
       "      <th>brainstem_IPH</th>\n",
       "      <th>brainstem_SAH</th>\n",
       "      <th>brainstem_Petechiae</th>\n",
       "      <th>brainstem_Edema</th>\n",
       "      <th>SDH_y</th>\n",
       "      <th>EDH</th>\n",
       "      <th>dtc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>87</td>\n",
       "      <td>132</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.52</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2476</td>\n",
       "      <td>229</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>35.2</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>nd</td>\n",
       "      <td>38.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>11685</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.83</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>37.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PAS DCA PAD DCA FC  DCA Shock index DCA Shock Index inversé.1  \\\n",
       "0     120      87     132             1.1                  0.91   \n",
       "1     110      60      60            0.55                  1.83   \n",
       "2     110      50     100            0.91                   1.1   \n",
       "3     120      90     120               1                     1   \n",
       "4     120      60     110            0.92                  1.09   \n",
       "\n",
       "  Shock index diastolique.1 GCS DCA GCS (M) DCA Température DCA Hémocue DCA  \\\n",
       "0                      1.52      15           6            37.2        13.7   \n",
       "1                         1      15           6            35.2          14   \n",
       "2                         2      13          nd            38.2        12.7   \n",
       "3                      1.33      15           6            37.8        12.8   \n",
       "4                      1.83      15           6            37.1        15.6   \n",
       "\n",
       "   ... infratentorial_SAH infratentorial_Petechiae infratentorial_Edema  \\\n",
       "0  ...                  0                        0                    0   \n",
       "1  ...                 15                        0                    0   \n",
       "2  ...                  0                        0                    0   \n",
       "3  ...                  0                        0                    0   \n",
       "4  ...                  0                        0                    0   \n",
       "\n",
       "  brainstem_IPH  brainstem_SAH  brainstem_Petechiae  brainstem_Edema  SDH_y  \\\n",
       "0             0              0                    0                0   2476   \n",
       "1             0              0                    0                0     43   \n",
       "2             0              0                    0                0    312   \n",
       "3             0              0                    0                0     11   \n",
       "4             0              0                    0                0    796   \n",
       "\n",
       "     EDH  dtc  \n",
       "0    229  0.0  \n",
       "1      0  0.0  \n",
       "2  11685  1.0  \n",
       "3      0  0.0  \n",
       "4      0  0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the conditions for dtc\n",
    "def calculate_dtc(row):\n",
    "    # Condition for dtc = NA\n",
    "    if ('nr' in [row['DTC Vd'], row['DTC IP']] or\n",
    "        'non réalisé' in [row['DTC Vd'], row['DTC IP']]):\n",
    "        return np.nan\n",
    "    # Condition for dtc = 1\n",
    "    if (row['DTC Vd'] == 'Pathologique' or row['DTC IP'] == 'Pathologique' or\n",
    "        (is_numeric(row['DTC Vd']) and float(row['DTC Vd']) < 30) or\n",
    "        (is_numeric(row['DTC IP']) and float(row['DTC IP']) > 1.2)):\n",
    "        return 1\n",
    "    # Default case for dtc = 0\n",
    "    return 0\n",
    "\n",
    "# Helper function to check if a value is numeric\n",
    "def is_numeric(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "# Apply the function row-wise to create the new column\n",
    "X_dca_and_segmentation['dtc'] = X_dca_and_segmentation.apply(calculate_dtc, axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "X_dca_and_segmentation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a75bab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values per column:\n",
      "PAS DCA                       14\n",
      "PAD DCA                       14\n",
      "FC  DCA                       17\n",
      "Shock index DCA               20\n",
      "Shock Index inversé.1         20\n",
      "Shock index diastolique.1     20\n",
      "GCS DCA                       30\n",
      "GCS (M) DCA                   33\n",
      "Température DCA              402\n",
      "Hémocue DCA                   37\n",
      "Dextro DCA (mmol/l)           75\n",
      "DTC Vd                       453\n",
      "DTC IP                       452\n",
      "Osmothérapie                 395\n",
      "supratentorial_IPH             0\n",
      "supratentorial_SAH             0\n",
      "supratentorial_Petechiae       0\n",
      "supratentorial_Edema           0\n",
      "infratentorial_IPH             0\n",
      "infratentorial_SAH             0\n",
      "infratentorial_Petechiae       0\n",
      "infratentorial_Edema           0\n",
      "brainstem_IPH                  0\n",
      "brainstem_SAH                  0\n",
      "brainstem_Petechiae            0\n",
      "brainstem_Edema                0\n",
      "SDH_y                          0\n",
      "EDH                            0\n",
      "dtc                          163\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert all columns to numeric, replacing non-numeric values and empty strings with NaN\n",
    "X_dca_and_segmentation = X_dca_and_segmentation.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "X_dca_and_segmentation.head()\n",
    "\n",
    "# Verify if there are NaN values\n",
    "print(f\"Number of NaN values per column:\\n{X_dca_and_segmentation.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d4796745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name  mortality\n",
      "0  P0000          0\n",
      "1  P0001          0\n",
      "2  P0002          0\n",
      "3  P0003          0\n",
      "4  P0004          0\n",
      "Outcome events : 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bettik/PROJECTS/pr-gin5_aini/fehrdelt/FastDiag/data_preprocessing_outcomes.py:236: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col] = data[col].replace({'1': 1, '0': 0, 'nd': np.nan, '8 Upper Good Recovery (Upper GR)': np.nan}).astype(float)\n",
      "/bettik/PROJECTS/pr-gin5_aini/fehrdelt/FastDiag/data_preprocessing_outcomes.py:236: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col] = data[col].replace({'1': 1, '0': 0, 'nd': np.nan, '8 Upper Good Recovery (Upper GR)': np.nan}).astype(float)\n",
      "/bettik/PROJECTS/pr-gin5_aini/fehrdelt/FastDiag/data_preprocessing_outcomes.py:236: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col] = data[col].replace({'1': 1, '0': 0, 'nd': np.nan, '8 Upper Good Recovery (Upper GR)': np.nan}).astype(float)\n"
     ]
    }
   ],
   "source": [
    "# Include column name\n",
    "X_dca_and_segmentation = pd.concat([X_dca_and_segmentation, data_full.iloc[:, 2]], axis=1)\n",
    "X = X_dca_and_segmentation.copy()\n",
    "y = get_mortality_6m()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a3038b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes with NaN in 'mortality': Index([], dtype='int64')\n",
      "Shape of y after cleaning: (566, 2)\n",
      "Shape of X after cleaning: (534, 30)\n",
      "Unique 'name' values in y: 562\n",
      "Unique 'name' values in X: 534\n",
      "Names in y but not in X: {'P0349', 'P0518', 'P0155', 'P0150', 'P0383', 'P0224', 'P0217', 'P0564', 'P0532', 'P0327', 'P0147', 'P0207', 'P0018', 'P0195', 'P0430', 'P0239', 'P0149', 'P0480', 'P0083', 'P0369', 'P0422', 'P0412', 'P0111', 'P0356', 'P0010', 'P0527', 'P0343', 'P0491'}\n",
      "Names in X but not in y: set()\n",
      "Shape of y after alignment: (536, 2)\n",
      "Shape of X after alignment: (534, 30)\n",
      "Number of duplicate names in y: 2\n",
      "Number of duplicate names in X: 0\n",
      "Shape of y after removing duplicates: (534, 2)\n",
      "Shape of X after removing duplicates: (534, 30)\n",
      "Are 'name' values aligned between y and X True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Identify indexes where 'mortality' is NaN in y\n",
    "nan_indexes = y.loc[pd.isna(y[\"mortality\"]), :].index\n",
    "print(f\"Indexes with NaN in 'mortality': {nan_indexes}\")\n",
    "\n",
    "# Drop rows with NaN in y\n",
    "y = y.drop(index=nan_indexes)\n",
    "\n",
    "# Ensure 'name' is the index or used for alignment\n",
    "X = X[~X['name'].isin(y.loc[nan_indexes, 'name'])]\n",
    "\n",
    "# Verify the shapes after cleaning\n",
    "print(f\"Shape of y after cleaning: {y.shape}\")\n",
    "print(f\"Shape of X after cleaning: {X.shape}\")\n",
    "\n",
    "# Vérifiez les valeurs uniques de 'name' dans y\n",
    "print(\"Unique 'name' values in y:\", y['name'].nunique())\n",
    "\n",
    "# Vérifiez les valeurs uniques de 'name' dans X\n",
    "print(\"Unique 'name' values in X:\", X['name'].nunique())\n",
    "\n",
    "# Noms dans y mais pas dans X\n",
    "missing_in_X = set(y['name']) - set(X['name'])\n",
    "print(f\"Names in y but not in X: {missing_in_X}\")\n",
    "\n",
    "# Noms dans X mais pas dans y\n",
    "missing_in_y = set(X['name']) - set(y['name'])\n",
    "print(f\"Names in X but not in y: {missing_in_y}\")\n",
    "\n",
    "# Trouver les noms communs\n",
    "common_names = set(y['name']).intersection(set(X['name']))\n",
    "\n",
    "# Filtrer y et X pour ne garder que les noms communs\n",
    "y = y[y['name'].isin(common_names)]\n",
    "X = X[X['name'].isin(common_names)]\n",
    "\n",
    "# Vérifiez les dimensions après nettoyage\n",
    "print(f\"Shape of y after alignment: {y.shape}\")\n",
    "print(f\"Shape of X after alignment: {X.shape}\")\n",
    "\n",
    "# Check for duplicates in 'name' in y\n",
    "print(\"Number of duplicate names in y:\", y['name'].duplicated().sum())\n",
    "\n",
    "# Check for duplicates in 'name' in X\n",
    "print(\"Number of duplicate names in X:\", X['name'].duplicated().sum())\n",
    "\n",
    "# Remove duplicates from both DataFrames\n",
    "y = y.drop_duplicates(subset=['name'])\n",
    "X = X.drop_duplicates(subset=['name'])\n",
    "\n",
    "# Verify the shapes again\n",
    "print(f\"Shape of y after removing duplicates: {y.shape}\")\n",
    "print(f\"Shape of X after removing duplicates: {X.shape}\")\n",
    "\n",
    "# Check if 'name' values are the same in both DataFrames\n",
    "common_names = set(y['name']) == set(X['name'])\n",
    "print(f\"Are 'name' values aligned between y and X {common_names}\")\n",
    "\n",
    "# Trier y et X par la colonne 'name'\n",
    "y = y.sort_values(by='name').reset_index(drop=True)\n",
    "X = X.sort_values(by='name').reset_index(drop=True)\n",
    "\n",
    "# Vérifier si les noms sont alignés\n",
    "print((y['name'].values == X['name'].values).all())\n",
    "\n",
    "# Drop the 'name' column from X\n",
    "#X_features = X.drop(columns=['name', 'mortalité J7'])\n",
    "X_features = X.drop(columns=['name'])\n",
    "\n",
    "# imputation with median \n",
    "X_features_imputed = X_features.fillna(X_features.median())\n",
    "\n",
    "# Drop the 'name' column from y (if it exists)\n",
    "y_outcome = y.drop(columns=['name'])\n",
    "\n",
    "# Ensure y_outcome is a 1D array\n",
    "y_outcome = y_outcome.values.ravel()  # Convert to 1D if using pandas DataFrame\n",
    "\n",
    "FOLDS = 5\n",
    "N_REPEATS = 3\n",
    "nb_total_samples = len(y_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7dca7dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAS DCA</th>\n",
       "      <th>PAD DCA</th>\n",
       "      <th>FC  DCA</th>\n",
       "      <th>Shock index DCA</th>\n",
       "      <th>Shock Index inversé.1</th>\n",
       "      <th>Shock index diastolique.1</th>\n",
       "      <th>GCS DCA</th>\n",
       "      <th>GCS (M) DCA</th>\n",
       "      <th>Température DCA</th>\n",
       "      <th>Hémocue DCA</th>\n",
       "      <th>...</th>\n",
       "      <th>infratentorial_SAH</th>\n",
       "      <th>infratentorial_Petechiae</th>\n",
       "      <th>infratentorial_Edema</th>\n",
       "      <th>brainstem_IPH</th>\n",
       "      <th>brainstem_SAH</th>\n",
       "      <th>brainstem_Petechiae</th>\n",
       "      <th>brainstem_Edema</th>\n",
       "      <th>SDH_y</th>\n",
       "      <th>EDH</th>\n",
       "      <th>dtc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.52</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2476</td>\n",
       "      <td>229</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>11685</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.83</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PAS DCA  PAD DCA  FC  DCA  Shock index DCA  Shock Index inversé.1  \\\n",
       "0    120.0     87.0    132.0             1.10                   0.91   \n",
       "1    110.0     60.0     60.0             0.55                   1.83   \n",
       "2    110.0     50.0    100.0             0.91                   1.10   \n",
       "3    120.0     90.0    120.0             1.00                   1.00   \n",
       "4    120.0     60.0    110.0             0.92                   1.09   \n",
       "\n",
       "   Shock index diastolique.1  GCS DCA  GCS (M) DCA  Température DCA  \\\n",
       "0                       1.52     15.0          6.0             37.2   \n",
       "1                       1.00     15.0          6.0             35.2   \n",
       "2                       2.00     13.0          NaN             38.2   \n",
       "3                       1.33     15.0          6.0             37.8   \n",
       "4                       1.83     15.0          6.0             37.1   \n",
       "\n",
       "   Hémocue DCA  ...  infratentorial_SAH  infratentorial_Petechiae  \\\n",
       "0         13.7  ...                   0                         0   \n",
       "1         14.0  ...                  15                         0   \n",
       "2         12.7  ...                   0                         0   \n",
       "3         12.8  ...                   0                         0   \n",
       "4         15.6  ...                   0                         0   \n",
       "\n",
       "   infratentorial_Edema  brainstem_IPH  brainstem_SAH  brainstem_Petechiae  \\\n",
       "0                     0              0              0                    0   \n",
       "1                     0              0              0                    0   \n",
       "2                     0              0              0                    0   \n",
       "3                     0              0              0                    0   \n",
       "4                     0              0              0                    0   \n",
       "\n",
       "   brainstem_Edema  SDH_y    EDH  dtc  \n",
       "0                0   2476    229  0.0  \n",
       "1                0     43      0  0.0  \n",
       "2                0    312  11685  1.0  \n",
       "3                0     11      0  0.0  \n",
       "4                0    796      0  0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dd31f236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoostingClassifier with hyperparameter gridsearch\n",
      "AUC (max): 0.89 +- 0.06\n",
      "F1 Score (max): 0.46 +- 0.11\n",
      "F2 Score (max): 0.53 +- 0.14\n",
      "Brier Score (min): 0.07 +- -0.02\n",
      "False negative: 2% +- 1\n",
      "False positive: 7% +- 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline_smote_under = Pipeline(steps=[('over', SMOTE()), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "#pipeline_smote_under = Pipeline(steps=[('over', SMOTENC(categorical_features=[\"fracas_du_bassin\", \"amputation\"])), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "\n",
    "\n",
    "inner_cv = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=5, random_state=1)\n",
    "\n",
    "p_grid = {\"model__learning_rate\": [0.01, 0.05, 0.08, 0.1, 0.2, 0.3, 0.5, 1], \"over__sampling_strategy\": [0.1, 0.2, 0.3], \"over__k_neighbors\":[3,5,8], \"under__sampling_strategy\":[0.3, 0.5, 0.7]}\n",
    "clf = GridSearchCV(estimator=pipeline_smote_under, param_grid=p_grid, scoring={'F2':ftwo_scorer}, refit='F2', cv=inner_cv)\n",
    "\n",
    "outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "nested_scores_smote_undersampling = cross_validate(clf, X_features_imputed, y_outcome, \n",
    "                                                scoring={'F2':ftwo_scorer, 'ROC_AUC':'roc_auc', 'Recall':'recall_macro', 'F1':'f1', 'Brier':\"neg_brier_score\", 'False_neg_scorer':false_neg_scorer, 'False_pos_scorer':false_pos_scorer}, \n",
    "                                                cv=outer_cv, n_jobs=-1, return_estimator=True, return_indices=True)\n",
    "\n",
    "print(\"HistGradientBoostingClassifier with hyperparameter gridsearch\")\n",
    "\n",
    "roc_auc_metric = np.mean(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "roc_auc_metric_std = np.std(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "print(f'AUC (max): {np.round(roc_auc_metric, 2)} +- {np.round(roc_auc_metric_std, 2)}')\n",
    "\n",
    "f1_score = np.mean(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "f1_score_std = np.std(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "print(f'F1 Score (max): {np.round(f1_score, 2)} +- {np.round(f1_score_std, 2)}')\n",
    "\n",
    "f2_score = np.mean(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "f2_score_std = np.std(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "print(f'F2 Score (max): {np.round(f2_score, 2)} +- {np.round(f2_score_std, 2)}')\n",
    "\n",
    "brier_score = -np.mean(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "brier_score_std = -np.std(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "print(f'Brier Score (min): {np.round(brier_score, 2)} +- {np.round(brier_score_std, 2)}')\n",
    "\n",
    "# test_False_neg_scorer returns the number of test false negatives -> to get a % we need to divide by the number of test samples*100\n",
    "false_neg_score = np.mean(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "false_neg_score_std = np.std(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "print(f'False negative: {int(np.round(false_neg_score, 0))}% +- {int(np.round(false_neg_score_std, 0))}')\n",
    "\n",
    "false_pos_score = np.mean(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "false_pos_score_std = np.std(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "print(f'False positive: {int(np.round(false_pos_score, 0))}% +- {int(np.round(false_pos_score_std, 0))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf37fcb",
   "metadata": {},
   "source": [
    "#### Confidence intervals with test set bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5db9fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_list = []\n",
    "\n",
    "for estimator in nested_scores_smote_undersampling[\"estimator\"]:\n",
    "    best_params_list.append(frozenset(estimator.best_params_.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "90e4a06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final chosen hyperparameters: {'over__sampling_strategy': 0.2, 'under__sampling_strategy': 0.7, 'model__learning_rate': 1, 'over__k_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Convert dict to a hashable tuple and count occurrences\n",
    "most_common_params = Counter(best_params_list).most_common(1)[0][0]\n",
    "final_params = dict(most_common_params)  # Convert back to dict\n",
    "\n",
    "\n",
    "print(\"Final chosen hyperparameters:\", final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "05b8b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('over', SMOTE(k_neighbors=5, sampling_strategy=0.2)), ('under', RandomUnderSampler(sampling_strategy=0.7)), ('model', HistGradientBoostingClassifier(learning_rate=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a1bf9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(pipeline, X_features_imputed, y_outcome, cv=20, method='predict_proba')[:,1]\n",
    "\n",
    "y_pred_binary = [1 if i>=0.5 else 0 for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62f8a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, confusion_matrix, roc_auc_score, f1_score, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2961b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=12345)\n",
    "idx = np.arange(len(y_outcome))\n",
    "\n",
    "y_pred = np.asarray(y_pred)\n",
    "y_pred_binary = np.asarray(y_pred_binary)\n",
    "y = np.asarray(y_outcome)\n",
    "X_dropped = np.asarray(X_features_imputed)\n",
    "\n",
    "test_roc_auc = []\n",
    "test_f1 = []\n",
    "test_ftwos = []\n",
    "test_brier = []\n",
    "test_false_neg = []\n",
    "test_false_pos = []\n",
    "\n",
    "for i in range(200): # bootstrap with 200 rounds: random sampling with replacement of the predictions\n",
    "\n",
    "    pred_idx = rng.choice(idx, size=len(idx), replace=True)\n",
    "    \n",
    "    roc_auc_test_boot = roc_auc_score(y_score=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    f1_test_boot = f1_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx])\n",
    "    f2_test_boot = fbeta_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx], beta=2)\n",
    "    brier_test_boot = brier_score_loss(y_proba=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    false_neg_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[1,0]\n",
    "    false_pos_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[0,1]\n",
    "    \n",
    "    test_roc_auc.append(roc_auc_test_boot)\n",
    "    test_f1.append(f1_test_boot)\n",
    "    test_ftwos.append(f2_test_boot)\n",
    "    test_brier.append(brier_test_boot)\n",
    "    test_false_neg.append(false_neg_test_boot/len(idx)*100)\n",
    "    test_false_pos.append(false_pos_test_boot/len(idx)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fe02f3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance\n",
      "\n",
      "ROC AUC:         0.88;   95% CI 0.81-0.94\n",
      "F1:              0.55;   95% CI 0.42-0.67\n",
      "F2:              0.61;   95% CI 0.47-0.74\n",
      "Brier loss:      0.06;   95% CI 0.04-0.08\n",
      "False negatives: 2.06%;  95% CI 1.12-3.19\n",
      "False negatives: 4.36%; 95% CI 2.43-6.37\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification performance\\n\")\n",
    "\n",
    "bootstrap_roc_auc_test_mean = np.mean(test_roc_auc)\n",
    "ci_lower = np.percentile(test_roc_auc, 2.5)     # 2.5 percentile (alpha=0.025)\n",
    "ci_upper = np.percentile(test_roc_auc, 97.5)\n",
    "print(f\"ROC AUC:         {bootstrap_roc_auc_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f1_test_mean = np.mean(test_f1)\n",
    "ci_lower = np.percentile(test_f1, 2.5)\n",
    "ci_upper = np.percentile(test_f1, 97.5)\n",
    "print(f\"F1:              {bootstrap_f1_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f2_test_mean = np.mean(test_ftwos)\n",
    "ci_lower = np.percentile(test_ftwos, 2.5)\n",
    "ci_upper = np.percentile(test_ftwos, 97.5)\n",
    "print(f\"F2:              {bootstrap_f2_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_brier_test_mean = np.mean(test_brier)\n",
    "ci_lower = np.percentile(test_brier, 2.5)\n",
    "ci_upper = np.percentile(test_brier, 97.5)\n",
    "print(f\"Brier loss:      {bootstrap_brier_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_neg_test_mean = np.mean(test_false_neg)\n",
    "ci_lower = np.percentile(test_false_neg, 2.5)\n",
    "ci_upper = np.percentile(test_false_neg, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_neg_test_mean:.2f}%;  95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_pos_test_mean = np.mean(test_false_pos)\n",
    "ci_lower = np.percentile(test_false_pos, 2.5)\n",
    "ci_upper = np.percentile(test_false_pos, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_pos_test_mean:.2f}%; 95% CI {ci_lower:.2f}-{ci_upper:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e16515c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
