{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "def confusion_matrix_scorer(clf, X, y):\n",
    "\n",
    "     y_pred = clf.predict(X)\n",
    "     cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "     return {'tn': cm[0, 0], 'fp': cm[0, 1],\n",
    "             'fn': cm[1, 0], 'tp': cm[1, 1]}\n",
    "\n",
    "def false_neg_scorer(clf, X, y):\n",
    "\n",
    "     y_pred = clf.predict(X)\n",
    "     cm = confusion_matrix(y, y_pred)\n",
    "     \n",
    "     return cm[1, 0]\n",
    "\n",
    "def false_pos_scorer(clf, X, y):\n",
    "\n",
    "     y_pred = clf.predict(X)\n",
    "     cm = confusion_matrix(y, y_pred)\n",
    "     \n",
    "     return cm[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Nom</th>\n",
       "      <th>Prénom</th>\n",
       "      <th>Date Naissance</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sexe</th>\n",
       "      <th>IPP</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Entrée venue</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>4</th>\n",
       "      <th>délai.3</th>\n",
       "      <th>LATA</th>\n",
       "      <th>délai.4</th>\n",
       "      <th>mortalité J7</th>\n",
       "      <th>mortalité J30</th>\n",
       "      <th>Mortalité 6 mois</th>\n",
       "      <th>GOSE J30</th>\n",
       "      <th>GOSE 6 mois</th>\n",
       "      <th>Remarques</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>GARRIGUES</td>\n",
       "      <td>BERNARD</td>\n",
       "      <td>11/19/1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>338510.0</td>\n",
       "      <td>2.000010e+12</td>\n",
       "      <td>8/5/2020 21:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8 Upper Good Recovery (Upper GR)</td>\n",
       "      <td>8 Upper Good Recovery (Upper GR)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>KONIECZNY CONTAMIN</td>\n",
       "      <td>LILIAN</td>\n",
       "      <td>11/21/1968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>111247.0</td>\n",
       "      <td>2.000010e+12</td>\n",
       "      <td>8/6/2020 11:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8 Upper Good Recovery (Upper GR)</td>\n",
       "      <td>8 Upper Good Recovery (Upper GR)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>AYEUL</td>\n",
       "      <td>JULIEN</td>\n",
       "      <td>6/14/1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>72080966.0</td>\n",
       "      <td>2.000010e+12</td>\n",
       "      <td>8/7/2020 21:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>max</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>MALICHEVA</td>\n",
       "      <td>MARIA</td>\n",
       "      <td>8/5/1978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>72081026.0</td>\n",
       "      <td>2.000010e+12</td>\n",
       "      <td>8/8/2020 19:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>nd</td>\n",
       "      <td>nd</td>\n",
       "      <td>nd</td>\n",
       "      <td>nd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>ELEZAAR</td>\n",
       "      <td>KHALIFA</td>\n",
       "      <td>11/17/1986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>72012454.0</td>\n",
       "      <td>2.000010e+12</td>\n",
       "      <td>8/9/2020 2:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8 Upper Good Recovery (Upper GR)</td>\n",
       "      <td>8 Upper Good Recovery (Upper GR)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 Nom   Prénom Date Naissance  Age Sexe  \\\n",
       "0          19           GARRIGUES  BERNARD     11/19/1941  NaN    M   \n",
       "1          20  KONIECZNY CONTAMIN   LILIAN     11/21/1968  NaN    M   \n",
       "2          22               AYEUL   JULIEN      6/14/1997  NaN    M   \n",
       "3          27           MALICHEVA    MARIA       8/5/1978  NaN    F   \n",
       "4          29             ELEZAAR  KHALIFA     11/17/1986  NaN    M   \n",
       "\n",
       "          IPP         Venue    Entrée venue  Unnamed: 9  ...    4 délai.3  \\\n",
       "0    338510.0  2.000010e+12  8/5/2020 21:36         NaN  ...  0.0     0.0   \n",
       "1    111247.0  2.000010e+12  8/6/2020 11:50         NaN  ...  0.0     0.0   \n",
       "2  72080966.0  2.000010e+12  8/7/2020 21:31         NaN  ...  0.0     0.0   \n",
       "3  72081026.0  2.000010e+12  8/8/2020 19:57         NaN  ...  0.0     0.0   \n",
       "4  72012454.0  2.000010e+12   8/9/2020 2:19         NaN  ...  0.0     0.0   \n",
       "\n",
       "  LATA délai.4  mortalité J7 mortalité J30 Mortalité 6 mois  \\\n",
       "0  0.0     0.0             0             0                0   \n",
       "1  0.0     0.0             0             0                0   \n",
       "2  0.0     0.0             0             0                0   \n",
       "3  0.0     0.0             0            nd               nd   \n",
       "4  0.0     0.0             0             0                0   \n",
       "\n",
       "                           GOSE J30                       GOSE 6 mois  \\\n",
       "0  8 Upper Good Recovery (Upper GR)  8 Upper Good Recovery (Upper GR)   \n",
       "1  8 Upper Good Recovery (Upper GR)  8 Upper Good Recovery (Upper GR)   \n",
       "2                               NaN                               max   \n",
       "3                                nd                                nd   \n",
       "4  8 Upper Good Recovery (Upper GR)  8 Upper Good Recovery (Upper GR)   \n",
       "\n",
       "  Remarques  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data_full = pd.read_csv(DATA_DIRECTORY+\"cleaned_data_full.csv\", skiprows=1)\n",
    "cleaned_data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude rows where the 'exclusion' column is not null\n",
    "cleaned_data_full = cleaned_data_full[cleaned_data_full['Exclusion'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'Nom', 'Prénom', 'Date Naissance', 'Age', 'Sexe', 'IPP', 'Venue', 'Entrée venue', 'Unnamed: 9', 'Exclusion', 'SAMU ', 'GRADE annoncé', 'Mécanisme accident ', 'Pénétrant', \"Site d'accueil \", 'PAS  SMUR ', 'PAD  SMUR ', 'FC SMUR ', 'FR SMUR', 'Shock Index SMUR', 'GCS SMUR ', 'GCS (M) SMUR ', 'Hémocue SMUR ', 'Shock Index inversé', 'Shock index diastolique', 'Anomalie pupille SMUR', 'Fracas bassin', 'Amputation', 'ACR SMUR', 'Hémorragie ext SMUR', 'Ischémie', 'Intubation prehosp', 'Expansion volémique', 'OsmoTH prehosp', 'Vasopresseur prehosp', 'PAS DCA', 'PAD DCA', 'FC  DCA', 'Shock index DCA', 'Shock Index inversé.1', 'Shock index diastolique.1', 'GCS DCA', 'GCS (M) DCA', 'Température DCA', 'Hémocue DCA', 'Dextro DCA (mmol/l)', 'DTC Vd', 'DTC IP', 'Osmothérapie', '1 : AIS Tête', '1 : AIS Tête.1', '1 : AIS Tête.2', '1 : AIS Tête.3', 'AIS rachis', 'AIS thorax', 'AIS abdo', 'AIS extrémités', 'ISS', 'IGS ', 'Admission ICU', 'Ventilation', 'ICP', 'Osmotherapy', 'CSF/EVD', 'deep sedation', 'Paralysis', 'Raise CPP/MAP challenge', 'Barbiturates', 'CraniectomyHypothermie', 'Unnamed: 70', 'Unnamed: 71', 'Unnamed: 72', 'Unnamed: 73', 'Unnamed: 74', 'Unnamed: 75', 'Marshal', 'Intrap H (IPH)', 'SDH', 'Epidural H (EDH)', 'Intraventr (IVH)', 'Subarach (SAH)', 'Petechiae (P)', 'Oedema (Od)', 'DAI', '1', 'délai', '2', 'délai.1', '3', 'délai.2', '4', 'délai.3', 'LATA', 'délai.4', 'mortalité J7', 'mortalité J30', 'Mortalité 6 mois', 'GOSE J30', 'GOSE 6 mois', 'Remarques']\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_data_full.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAS  SMUR</th>\n",
       "      <th>PAD  SMUR</th>\n",
       "      <th>FC SMUR</th>\n",
       "      <th>FR SMUR</th>\n",
       "      <th>Shock Index SMUR</th>\n",
       "      <th>GCS SMUR</th>\n",
       "      <th>GCS (M) SMUR</th>\n",
       "      <th>Hémocue SMUR</th>\n",
       "      <th>Shock Index inversé</th>\n",
       "      <th>Shock index diastolique</th>\n",
       "      <th>Anomalie pupille SMUR</th>\n",
       "      <th>Fracas bassin</th>\n",
       "      <th>Amputation</th>\n",
       "      <th>ACR SMUR</th>\n",
       "      <th>Hémorragie ext SMUR</th>\n",
       "      <th>Ischémie</th>\n",
       "      <th>Intubation prehosp</th>\n",
       "      <th>Expansion volémique</th>\n",
       "      <th>OsmoTH prehosp</th>\n",
       "      <th>Vasopresseur prehosp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190</td>\n",
       "      <td>103</td>\n",
       "      <td>137</td>\n",
       "      <td>nd</td>\n",
       "      <td>0.72</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>nd</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>49</td>\n",
       "      <td>56</td>\n",
       "      <td>nd</td>\n",
       "      <td>0.64</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>nd</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>nd</td>\n",
       "      <td>1</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>64</td>\n",
       "      <td>120</td>\n",
       "      <td>nd</td>\n",
       "      <td>1.19</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110</td>\n",
       "      <td>71</td>\n",
       "      <td>107</td>\n",
       "      <td>18</td>\n",
       "      <td>0.97</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PAS  SMUR  PAD  SMUR  FC SMUR  FR SMUR Shock Index SMUR GCS SMUR   \\\n",
       "0        190        103      137      nd             0.72        15   \n",
       "1         87         49       56      nd             0.64        15   \n",
       "2        100         60      100      17                1        15   \n",
       "3        101         64      120      nd             1.19        14   \n",
       "4        110         71      107      18             0.97        15   \n",
       "\n",
       "  GCS (M) SMUR  Hémocue SMUR  Shock Index inversé Shock index diastolique  \\\n",
       "0             6            nd                1.39                    1.33   \n",
       "1             6            nd                1.55                    1.14   \n",
       "2             6            nd                   1                    1.67   \n",
       "3             6          13.1                0.84                    1.88   \n",
       "4             6          15.8                1.03                    1.51   \n",
       "\n",
       "  Anomalie pupille SMUR  Fracas bassin  Amputation  ACR SMUR  \\\n",
       "0                     0            0.0         0.0       0.0   \n",
       "1                     0            0.0         0.0       0.0   \n",
       "2                     0            0.0         0.0       0.0   \n",
       "3                     0            0.0         0.0       0.0   \n",
       "4                     0            0.0         0.0       0.0   \n",
       "\n",
       "   Hémorragie ext SMUR  Ischémie  Intubation prehosp Expansion volémique  \\\n",
       "0                  0.0       0.0                 0.0                 500   \n",
       "1                  0.0       0.0                 0.0                 250   \n",
       "2                  0.0       0.0                 0.0                 250   \n",
       "3                  0.0       0.0                 0.0                 250   \n",
       "4                  0.0       0.0                 0.0                 500   \n",
       "\n",
       "   OsmoTH prehosp  Vasopresseur prehosp  \n",
       "0             0.0                   0.0  \n",
       "1             0.0                   0.0  \n",
       "2             0.0                   0.0  \n",
       "3             0.0                   0.0  \n",
       "4             0.0                   0.0  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only some columns \n",
    "X_traumatrix = cleaned_data_full_filtered[['PAS  SMUR ', 'GCS SMUR ', 'Hémorragie ext SMUR', 'Vasopresseur prehosp', \n",
    "                                           'SDH', 'Petechiae (P)', 'Intrap H (IPH)', 'Subarach (SAH)', '']]\n",
    "X_traumatrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Variable  Missing Values  \\\n",
      "PAS  SMUR                             PAS  SMUR               40   \n",
      "PAD  SMUR                             PAD  SMUR               50   \n",
      "FC SMUR                                 FC SMUR               42   \n",
      "FR SMUR                                  FR SMUR             513   \n",
      "Shock Index SMUR                Shock Index SMUR              54   \n",
      "GCS SMUR                               GCS SMUR               16   \n",
      "GCS (M) SMUR                       GCS (M) SMUR               30   \n",
      "Hémocue SMUR                       Hémocue SMUR              251   \n",
      "Shock Index inversé          Shock Index inversé              53   \n",
      "Shock index diastolique  Shock index diastolique              62   \n",
      "Anomalie pupille SMUR      Anomalie pupille SMUR              15   \n",
      "Fracas bassin                      Fracas bassin              13   \n",
      "Amputation                            Amputation              11   \n",
      "ACR SMUR                                ACR SMUR              10   \n",
      "Hémorragie ext SMUR          Hémorragie ext SMUR              11   \n",
      "Ischémie                                Ischémie              11   \n",
      "Intubation prehosp            Intubation prehosp              10   \n",
      "Expansion volémique          Expansion volémique              17   \n",
      "OsmoTH prehosp                    OsmoTH prehosp              11   \n",
      "Vasopresseur prehosp        Vasopresseur prehosp              11   \n",
      "\n",
      "                                                             Unique Values  \\\n",
      "PAS  SMUR                [190.0, 87.0, 100.0, 101.0, 110.0, 114.0, 74.0...   \n",
      "PAD  SMUR                [103.0, 49.0, 60.0, 64.0, 71.0, 79.0, 40.0, na...   \n",
      "FC SMUR                  [137.0, 56.0, 100.0, 120.0, 107.0, 83.0, 60.0,...   \n",
      "FR SMUR                  [nan, 17.0, 18.0, 16.0, 22.0, 25.0, 20.0, 21.0...   \n",
      "Shock Index SMUR         [0.72, 0.64, 1.0, 1.19, 0.97, 0.73, 1.62, 0.67...   \n",
      "GCS SMUR                 [15.0, 14.0, nan, 13.0, 12.0, 7.0, 6.0, 3.0, 1...   \n",
      "GCS (M) SMUR               [6.0, nan, 1.0, 5.0, 4.0, 2.0, 15.0, 3.0, 14.0]   \n",
      "Hémocue SMUR             [nan, 13.1, 15.8, 14.6, 12.0, 13.3, 14.0, 11.1...   \n",
      "Shock Index inversé      [1.39, 1.55, 1.0, 0.84, 1.03, 1.37, 0.62, 1.5,...   \n",
      "Shock index diastolique  [1.33, 1.14, 1.67, 1.88, 1.51, 1.05, 3.0, 1.0,...   \n",
      "Anomalie pupille SMUR                                      [0.0, 1.0, nan]   \n",
      "Fracas bassin                                              [0.0, 1.0, nan]   \n",
      "Amputation                                                 [0.0, nan, 2.0]   \n",
      "ACR SMUR                                              [0.0, 1.0, nan, 3.0]   \n",
      "Hémorragie ext SMUR                                   [0.0, 1.0, nan, 4.0]   \n",
      "Ischémie                                              [0.0, 1.0, nan, 5.0]   \n",
      "Intubation prehosp                                    [0.0, 1.0, nan, 6.0]   \n",
      "Expansion volémique      [500.0, 250.0, nan, 1250.0, 1000.0, 0.0, 750.0...   \n",
      "OsmoTH prehosp                                 [0.0, 1.0, nan, 250.0, 8.0]   \n",
      "Vasopresseur prehosp                                       [0.0, 1.0, nan]   \n",
      "\n",
      "                         Min Value  Max Value  \n",
      "PAS  SMUR                      0.0     200.00  \n",
      "PAD  SMUR                      0.0     135.00  \n",
      "FC SMUR                        0.0     220.00  \n",
      "FR SMUR                        0.0      72.00  \n",
      "Shock Index SMUR               0.0     100.00  \n",
      "GCS SMUR                       3.0      18.00  \n",
      "GCS (M) SMUR                   1.0      15.00  \n",
      "Hémocue SMUR                   6.0    1032.00  \n",
      "Shock Index inversé            0.0      21.78  \n",
      "Shock index diastolique        0.0     100.00  \n",
      "Anomalie pupille SMUR          0.0       1.00  \n",
      "Fracas bassin                  0.0       1.00  \n",
      "Amputation                     0.0       2.00  \n",
      "ACR SMUR                       0.0       3.00  \n",
      "Hémorragie ext SMUR            0.0       4.00  \n",
      "Ischémie                       0.0       5.00  \n",
      "Intubation prehosp             0.0       6.00  \n",
      "Expansion volémique            0.0    2000.00  \n",
      "OsmoTH prehosp                 0.0     250.00  \n",
      "Vasopresseur prehosp           0.0       1.00  \n"
     ]
    }
   ],
   "source": [
    "# Convert all variables in X_prehosp to numeric, coercing invalid entries to NaN\n",
    "X_traumatrix_numeric = X_traumatrix.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Count missing values (NA) for each variable in X_prehosp\n",
    "na_counts = X_traumatrix_numeric.isna().sum()\n",
    "\n",
    "# Get unique values for each variable in X_prehosp to check for potential outliers\n",
    "unique_values = {col: X_traumatrix_numeric[col].unique() for col in X_traumatrix_numeric.columns}\n",
    "\n",
    "# Calculate min and max for each variable in X_prehosp_numeric\n",
    "min_values = X_traumatrix_numeric.min()\n",
    "max_values = X_traumatrix_numeric.max()\n",
    "\n",
    "# Create the summary DataFrame with min, max, missing values, and unique values\n",
    "summary = pd.DataFrame({\n",
    "    \"Variable\": X_traumatrix_numeric.columns,\n",
    "    \"Missing Values\": na_counts,\n",
    "    \"Unique Values\": [list(unique_values[col]) for col in X_traumatrix_numeric.columns],\n",
    "    \"Min Value\": min_values,\n",
    "    \"Max Value\": max_values\n",
    "})\n",
    "\n",
    "# Display the summary\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les limites maximales pour les colonnes\n",
    "capping_limits = {\n",
    "    \"Shock Index SMUR\": 3,\n",
    "    \"GCS SMUR \": 15,\n",
    "    \"GCS (M) SMUR \": 6,\n",
    "    \"Shock Index inversé\": 3,\n",
    "    \"Shock index diastolique\": 3,\n",
    "    \"Amputation\": 1,\n",
    "    \"ACR SMUR\": 1,\n",
    "    \"Hémorragie ext SMUR\": 1,\n",
    "    \"Ischémie\": 1,\n",
    "    \"Intubation prehosp\": 1,\n",
    "    \"OsmoTH prehosp\": 1,\n",
    "    \"Vasopresseur prehosp\": 1\n",
    "}\n",
    "\n",
    "# Appliquer le capping\n",
    "for column, max_value in capping_limits.items():\n",
    "    if column in X_prehosp_numeric.columns:\n",
    "        X_prehosp_numeric[column] = X_prehosp_numeric[column].clip(upper=max_value)\n",
    "    else:\n",
    "        print(f\"Warning: Column '{column}' not found in DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation terminée.\n"
     ]
    }
   ],
   "source": [
    "# Définir les stratégies d’imputation\n",
    "imputation_strategies = {\n",
    "    \"PAS  SMUR \": \"median\",\n",
    "    \"PAD  SMUR \": \"median\",\n",
    "    \"FC SMUR \": \"median\",\n",
    "    \"Shock Index SMUR\": \"median\",\n",
    "    \"GCS SMUR \": \"median\",\n",
    "    \"GCS (M) SMUR \": \"median\",\n",
    "    \"Shock Index inversé\": \"median\",\n",
    "    \"Shock index diastolique\": \"median\",\n",
    "    \"Anomalie pupille SMUR\": 0,\n",
    "    \"Fracas bassin\": 0,\n",
    "    \"Amputation\": 0,\n",
    "    \"ACR SMUR\": 0,\n",
    "    \"Hémorragie ext SMUR\": 0,\n",
    "    \"Ischémie\": 0,\n",
    "    \"Intubation prehosp\": 0,\n",
    "    \"Expansion volémique\": \"median\",\n",
    "    \"OsmoTH prehosp\": 0,\n",
    "    \"Vasopresseur prehosp\": 0\n",
    "}\n",
    "\n",
    "# Appliquer l’imputation\n",
    "for column, strategy in imputation_strategies.items():\n",
    "    if column in X_prehosp_numeric.columns:\n",
    "        if strategy == \"median\":\n",
    "            X_prehosp_numeric[column] = X_prehosp_numeric[column].fillna(X_prehosp_numeric[column].median())\n",
    "        else:\n",
    "            X_prehosp_numeric[column] = X_prehosp_numeric[column].fillna(strategy)\n",
    "    else:\n",
    "        print(f\"Warning: Column '{column}' not found in DataFrame.\")\n",
    "\n",
    "# Vérifiez les résultats de l’imputation\n",
    "print(\"Imputation terminée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAS  SMUR                    0\n",
      "PAD  SMUR                    0\n",
      "FC SMUR                      0\n",
      "FR SMUR                    513\n",
      "Shock Index SMUR             0\n",
      "GCS SMUR                     0\n",
      "GCS (M) SMUR                 0\n",
      "Hémocue SMUR               251\n",
      "Shock Index inversé          0\n",
      "Shock index diastolique      0\n",
      "Anomalie pupille SMUR        0\n",
      "Fracas bassin                0\n",
      "Amputation                   0\n",
      "ACR SMUR                     0\n",
      "Hémorragie ext SMUR          0\n",
      "Ischémie                     0\n",
      "Intubation prehosp           0\n",
      "Expansion volémique          0\n",
      "OsmoTH prehosp               0\n",
      "Vasopresseur prehosp         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "na_counts = X_traumatrix_numeric.isna().sum()\n",
    "print(na_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes à supprimer\n",
    "columns_to_drop = [\"FR SMUR\", \"Hémocue SMUR \"]\n",
    "\n",
    "# Suppression si elles existent dans le DataFrame\n",
    "columns_existing = [col for col in columns_to_drop if col in X_prehosp_numeric.columns]\n",
    "X_prehosp_numeric = X_prehosp_numeric.drop(columns=columns_existing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TILSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIL 0</th>\n",
       "      <th>TIL 1</th>\n",
       "      <th>TIL 2</th>\n",
       "      <th>TIL 3</th>\n",
       "      <th>TIL 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TIL 0  TIL 1  TIL 2  TIL 3 TIL 4\n",
       "0    NaN    NaN    NaN    NaN   NaN\n",
       "1    0.0    0.0    0.0    0.0     0\n",
       "2    0.0    0.0    0.0    0.0     0\n",
       "3    0.0    0.0    0.0    0.0     0\n",
       "4    0.0    0.0    0.0    0.0     0"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIL = pd.read_csv(DATA_DIRECTORY+\"cleaned_data_full.csv\", usecols=range(71,76))\n",
    "TIL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y\n",
      "0  0\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "outcome events : y    46\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create y based on the conditions: TIL 2 = 1 or TIL 3 = 1 or TIL 4 = 1\n",
    "y = pd.DataFrame()\n",
    "y[\"y\"] = ((TIL.iloc[:, 2] == 1) | (TIL.iloc[:, 3] == 1) | (TIL.iloc[:, 4] == 1)).astype(int)\n",
    "\n",
    "# Verify the first few rows of y\n",
    "print(y.head())\n",
    "\n",
    "# Outcome event\n",
    "event_count = (y == 1.00).sum()\n",
    "print(f\"outcome events : {event_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y\n",
      "0  NaN\n",
      "1  0.0\n",
      "2  0.0\n",
      "3  0.0\n",
      "4  0.0\n"
     ]
    }
   ],
   "source": [
    "# Create y based on the conditions and propagate NA values\n",
    "y = pd.DataFrame(index=TIL.index)  # Keep the same indexing as TIL\n",
    "\n",
    "# Apply the conditions, setting NA in y if there are any NA values in the relevant TIL columns\n",
    "y[\"y\"] = TIL.iloc[:, [0, 1, 2, 3, 4]].apply(\n",
    "    lambda row: 1 if (row.iloc[2] == 1 or row.iloc[3] == 1 or row.iloc[4] == 1) else 0, axis=1\n",
    ")\n",
    "\n",
    "# Set y to NaN if any NA exists in the relevant columns\n",
    "y.loc[TIL.iloc[:, [0, 1, 2, 3, 4]].isnull().any(axis=1), \"y\"] = pd.NA\n",
    "\n",
    "# Verify the first few rows of y\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after cleaning: 545\n"
     ]
    }
   ],
   "source": [
    "# Align indexes between y and X_prehosp_numeric\n",
    "X_prehosp_numeric, y = X_prehosp_numeric.align(y, join=\"inner\", axis=0)\n",
    "\n",
    "# Identify rows where any NaN exists in y\n",
    "nan_and_nd_indexes = y.loc[y.isna().any(axis=1)].index\n",
    "\n",
    "# Drop rows with NaN from both y and X_prehosp_numeric\n",
    "y = y.drop(index=nan_and_nd_indexes)\n",
    "X_prehosp_numeric = X_prehosp_numeric.drop(index=nan_and_nd_indexes)\n",
    "\n",
    "# Check if the number of rows matches\n",
    "assert X_prehosp_numeric.shape[0] == y.shape[0], \"Number of rows in X and y do not match!\"\n",
    "\n",
    "print(f\"Number of rows after cleaning: {X_prehosp_numeric.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.to_numpy().ravel()  # Convert y to a 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (545,)\n"
     ]
    }
   ],
   "source": [
    "print(type(y), y.shape)  # Type should be numpy.ndarray and shape should be (n_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5\n",
    "N_REPEATS = 3\n",
    "nb_total_samples = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline_smote_under = Pipeline(steps=[('over', SMOTE()), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "#pipeline_smote_under = Pipeline(steps=[('over', SMOTENC(categorical_features=[\"fracas_du_bassin\", \"amputation\"])), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "\n",
    "\n",
    "inner_cv = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=5, random_state=1)\n",
    "\n",
    "p_grid = {\"model__learning_rate\": [0.01, 0.05, 0.08, 0.1, 0.2, 0.3, 0.5, 1], \"over__sampling_strategy\": [0.1, 0.2, 0.3], \"over__k_neighbors\":[3,5,8], \"under__sampling_strategy\":[0.3, 0.5, 0.7]}\n",
    "clf = GridSearchCV(estimator=pipeline_smote_under, param_grid=p_grid, scoring={'F2':ftwo_scorer}, refit='F2', cv=inner_cv)\n",
    "\n",
    "outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "nested_scores_smote_undersampling = cross_validate(clf, X_prehosp_numeric, y, scoring={'F2':ftwo_scorer, 'ROC_AUC':'roc_auc', 'Recall':'recall_macro', 'F1':'f1', 'Brier':\"neg_brier_score\", 'False_neg_scorer':false_neg_scorer, 'False_pos_scorer':false_pos_scorer}, cv=outer_cv, n_jobs=-1)\n",
    "\n",
    "print(\"segmentation volumes: HistGradientBoostingClassifier with hyperparameter gridsearch\")\n",
    "\n",
    "roc_auc_metric = np.mean(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "roc_auc_metric_std = np.std(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "print(f'AUC (max): {np.round(roc_auc_metric, 2)} +- {np.round(roc_auc_metric_std, 2)}')\n",
    "\n",
    "f1_score = np.mean(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "f1_score_std = np.std(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "print(f'F1 Score (max): {np.round(f1_score, 2)} +- {np.round(f1_score_std, 2)}')\n",
    "\n",
    "f2_score = np.mean(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "f2_score_std = np.std(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "print(f'F2 Score (max): {np.round(f2_score, 2)} +- {np.round(f2_score_std, 2)}')\n",
    "\n",
    "brier_score = -np.mean(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "brier_score_std = -np.std(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "print(f'Brier Score (min): {np.round(brier_score, 2)} +- {np.round(brier_score_std, 2)}')\n",
    "\n",
    "# test_False_neg_scorer returns the number of test false negatives -> to get a % we need to divide by the number of test samples*100\n",
    "false_neg_score = np.mean(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "false_neg_score_std = np.std(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "print(f'False negative: {int(np.round(false_neg_score, 0))}% +- {int(np.round(false_neg_score_std, 0))}')\n",
    "\n",
    "false_pos_score = np.mean(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "false_pos_score_std = np.std(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "print(f'False positive: {int(np.round(false_pos_score, 0))}% +- {int(np.round(false_pos_score_std, 0))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admission ICU</th>\n",
       "      <th>Ventilation</th>\n",
       "      <th>ICP</th>\n",
       "      <th>Osmotherapy</th>\n",
       "      <th>CSF/EVD</th>\n",
       "      <th>deep sedation</th>\n",
       "      <th>Paralysis</th>\n",
       "      <th>Raise CPP/MAP challenge</th>\n",
       "      <th>Barbiturates</th>\n",
       "      <th>CraniectomyHypothermie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Admission ICU  Ventilation  ICP  Osmotherapy  CSF/EVD  deep sedation  \\\n",
       "0            1.0          0.0  0.0          0.0      0.0            0.0   \n",
       "1            0.0          0.0  0.0          0.0      0.0            0.0   \n",
       "2            1.0          0.0  0.0          0.0      0.0            0.0   \n",
       "3            0.0          0.0  0.0          0.0      0.0            0.0   \n",
       "4            0.0          0.0  0.0          0.0      0.0            0.0   \n",
       "\n",
       "   Paralysis  Raise CPP/MAP challenge  Barbiturates CraniectomyHypothermie  \n",
       "0        0.0                      0.0           0.0                      0  \n",
       "1        0.0                      0.0           0.0                      0  \n",
       "2        0.0                      0.0           0.0                      0  \n",
       "3        0.0                      0.0           0.0                      0  \n",
       "4        0.0                      0.0           0.0                      0  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIER = pd.read_csv(DATA_DIRECTORY+\"cleaned_data_full.csv\", usecols=range(60,70), skiprows=1)\n",
    "TIER.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y\n",
      "0  0.0\n",
      "1  0.0\n",
      "2  0.0\n",
      "3  0.0\n",
      "4  0.0\n"
     ]
    }
   ],
   "source": [
    "# Create y based on the conditions and propagate NA values\n",
    "y = pd.DataFrame(index=TIER.index)  # Keep the same indexing as TIL\n",
    "\n",
    "# Apply the conditions, setting NA in y if there are any NA values in the relevant TIL columns\n",
    "y[\"y\"] = TIER.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]].apply(\n",
    "    lambda row: 1 if (row.iloc[6] == 1 or row.iloc[7] == 1 or row.iloc[8] == 1 or row.iloc[9] == 1) else 0, axis=1\n",
    ")\n",
    "\n",
    "# Set y to NaN if any NA exists in the relevant columns\n",
    "y.loc[TIER.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]].isnull().any(axis=1), \"y\"] = pd.NA\n",
    "\n",
    "# Verify the first few rows of y\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome events : y    33\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Outcome event\n",
    "event_count = (y == 1.00).sum()\n",
    "print(f\"outcome events : {event_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after cleaning: 558\n",
      "<class 'numpy.ndarray'> (558,)\n"
     ]
    }
   ],
   "source": [
    "# Align indexes between y and X_prehosp_numeric\n",
    "X_prehosp_numeric, y = X_prehosp_numeric.align(y, join=\"inner\", axis=0)\n",
    "\n",
    "# Identify rows where any NaN exists in y\n",
    "nan_and_nd_indexes = y.loc[y.isna().any(axis=1)].index\n",
    "\n",
    "# Drop rows with NaN from both y and X_prehosp_numeric\n",
    "y = y.drop(index=nan_and_nd_indexes)\n",
    "X_prehosp_numeric = X_prehosp_numeric.drop(index=nan_and_nd_indexes)\n",
    "\n",
    "# Check if the number of rows matches\n",
    "assert X_prehosp_numeric.shape[0] == y.shape[0], \"Number of rows in X and y do not match!\"\n",
    "\n",
    "print(f\"Number of rows after cleaning: {X_prehosp_numeric.shape[0]}\")\n",
    "\n",
    "y = y.to_numpy().ravel()  # Convert y to a 1D array\n",
    "\n",
    "print(type(y), y.shape)  # Type should be numpy.ndarray and shape should be (n_samples,)\n",
    "\n",
    "FOLDS = 5\n",
    "N_REPEATS = 3\n",
    "nb_total_samples = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmentation volumes: HistGradientBoostingClassifier with hyperparameter gridsearch\n",
      "AUC (max): 0.83 +- 0.09\n",
      "F1 Score (max): 0.38 +- 0.07\n",
      "F2 Score (max): 0.54 +- 0.1\n",
      "Brier Score (min): 0.11 +- -0.01\n",
      "False negative: 1% +- 1\n",
      "False positive: 13% +- 4\n"
     ]
    }
   ],
   "source": [
    "pipeline_smote_under = Pipeline(steps=[('over', SMOTE()), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "#pipeline_smote_under = Pipeline(steps=[('over', SMOTENC(categorical_features=[\"fracas_du_bassin\", \"amputation\"])), ('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', HistGradientBoostingClassifier())])\n",
    "\n",
    "\n",
    "inner_cv = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=5, random_state=1)\n",
    "\n",
    "p_grid = {\"model__learning_rate\": [0.01, 0.05, 0.08, 0.1, 0.2, 0.3, 0.5, 1], \"over__sampling_strategy\": [0.1, 0.2, 0.3], \"over__k_neighbors\":[3,5,8], \"under__sampling_strategy\":[0.3, 0.5, 0.7]}\n",
    "clf = GridSearchCV(estimator=pipeline_smote_under, param_grid=p_grid, scoring={'F2':ftwo_scorer}, refit='F2', cv=inner_cv)\n",
    "\n",
    "outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "nested_scores_smote_undersampling = cross_validate(clf, X_prehosp_numeric, y, scoring={'F2':ftwo_scorer, 'ROC_AUC':'roc_auc', 'Recall':'recall_macro', 'F1':'f1', 'Brier':\"neg_brier_score\", 'False_neg_scorer':false_neg_scorer, 'False_pos_scorer':false_pos_scorer}, cv=outer_cv, n_jobs=-1)\n",
    "\n",
    "print(\"segmentation volumes: HistGradientBoostingClassifier with hyperparameter gridsearch\")\n",
    "\n",
    "roc_auc_metric = np.mean(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "roc_auc_metric_std = np.std(nested_scores_smote_undersampling[\"test_ROC_AUC\"])\n",
    "print(f'AUC (max): {np.round(roc_auc_metric, 2)} +- {np.round(roc_auc_metric_std, 2)}')\n",
    "\n",
    "f1_score = np.mean(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "f1_score_std = np.std(nested_scores_smote_undersampling[\"test_F1\"])\n",
    "print(f'F1 Score (max): {np.round(f1_score, 2)} +- {np.round(f1_score_std, 2)}')\n",
    "\n",
    "f2_score = np.mean(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "f2_score_std = np.std(nested_scores_smote_undersampling[\"test_F2\"])\n",
    "print(f'F2 Score (max): {np.round(f2_score, 2)} +- {np.round(f2_score_std, 2)}')\n",
    "\n",
    "brier_score = -np.mean(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "brier_score_std = -np.std(nested_scores_smote_undersampling[\"test_Brier\"])\n",
    "print(f'Brier Score (min): {np.round(brier_score, 2)} +- {np.round(brier_score_std, 2)}')\n",
    "\n",
    "# test_False_neg_scorer returns the number of test false negatives -> to get a % we need to divide by the number of test samples*100\n",
    "false_neg_score = np.mean(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "false_neg_score_std = np.std(nested_scores_smote_undersampling[\"test_False_neg_scorer\"])*100/(nb_total_samples/FOLDS) \n",
    "print(f'False negative: {int(np.round(false_neg_score, 0))}% +- {int(np.round(false_neg_score_std, 0))}')\n",
    "\n",
    "false_pos_score = np.mean(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "false_pos_score_std = np.std(nested_scores_smote_undersampling[\"test_False_pos_scorer\"])*100/(nb_total_samples/FOLDS)\n",
    "print(f'False positive: {int(np.round(false_pos_score, 0))}% +- {int(np.round(false_pos_score_std, 0))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
