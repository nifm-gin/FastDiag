{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import fbeta_score, confusion_matrix, roc_auc_score, f1_score, brier_score_loss\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"/home/fehrdelt/data_ssd/data/clinical_data/Full/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df = pd.read_csv(DATA_DIRECTORY+\"combined_clinical_data_volumes_outcome_TTS_ANTS_hist_match.csv\", usecols=range(2,31))\n",
    "y = df = pd.read_csv(DATA_DIRECTORY+\"combined_clinical_data_volumes_outcome_TTS_ANTS_hist_match.csv\", usecols=[31])\n",
    "#X.head()\n",
    "#y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_indexes = y.loc[pd.isna(y[\"outcome_neurochir_pic\"]), :].index # indexes where there is a nan value.\n",
    "\n",
    "y = y.dropna()\n",
    "X_dropped = X.drop(nan_indexes)\n",
    "\n",
    "y = y['outcome_neurochir_pic'].to_numpy()\n",
    "y = [int(i) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models with the best hyperparameters using cross validation\n",
    "pipeline = Pipeline(steps=[('imputer', SimpleImputer(missing_values=np.nan, strategy='median')), \n",
    "                           #('feature_selection', SelectKBest(mutual_info_classif, k=8)), \n",
    "                           ('imbalance', SMOTEENN()), \n",
    "                           ('model', GradientBoostingClassifier(learning_rate=1.0023, max_depth=3, min_samples_leaf=3, min_samples_split=4, n_estimators=143))])\n",
    "\n",
    "\n",
    "y_pred = cross_val_predict(pipeline, X_dropped, y, cv=20, method='predict_proba')[:,1]\n",
    "\n",
    "y_pred_binary = [1 if i>=0.5 else 0 for i in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence Intervals: Bootstrapping the Test Set Predictions \n",
    "\n",
    "https://sebastianraschka.com/blog/2022/confidence-intervals-for-ml.html#method-3-bootstrapping-the-test-set-predictions\n",
    "\n",
    "Here, we pick our lower and upper confidence bounds as follows:\n",
    "\n",
    "$\\text{Metric}_{lower}=\\alpha_{1}\\text{th}$ percentile of the $\\text{Metric}_{boot}$ distribution; \\\n",
    "$\\text{Metric}_{upper}=\\alpha_{2}\\text{th}$ percentile of the $\\text{Metric}_{boot}$ distribution;\n",
    "\n",
    "\n",
    "Where $\\alpha_1 = \\alpha$ and $\\alpha_2 = 1-\\alpha$ \\\n",
    "And $\\alpha$ is our degree of confidence to compute the $100*(1âˆ’2\\alpha)$ confidence interval. \\\n",
    "For instance, to compute a $95\\%$ confidence interval, we pick $\\alpha=0.025$ to obtain the 2.5th and 97.5th percentiles of the b bootstrap samples distribution as our upper and lower confidence bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=12345)\n",
    "idx = np.arange(len(y))\n",
    "\n",
    "y_pred = np.asarray(y_pred)\n",
    "y_pred_binary = np.asarray(y_pred_binary)\n",
    "y = np.asarray(y)\n",
    "X = np.asarray(X)\n",
    "X_dropped = np.asarray(X_dropped)\n",
    "\n",
    "test_roc_auc = []\n",
    "test_f1 = []\n",
    "test_ftwos = []\n",
    "test_brier = []\n",
    "test_false_neg = []\n",
    "test_false_pos = []\n",
    "\n",
    "for i in range(200): # bootstrap with 200 rounds: random sampling with replacement of the predictions\n",
    "\n",
    "    pred_idx = rng.choice(idx, size=len(idx), replace=True)\n",
    "    \n",
    "    roc_auc_test_boot = roc_auc_score(y_score=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    f1_test_boot = f1_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx])\n",
    "    f2_test_boot = fbeta_score(y_pred=y_pred_binary[pred_idx], y_true=y[pred_idx], beta=2)\n",
    "    brier_test_boot = brier_score_loss(y_proba=y_pred[pred_idx], y_true=y[pred_idx])\n",
    "    false_neg_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[1,0]\n",
    "    false_pos_test_boot = confusion_matrix(y[pred_idx], y_pred_binary[pred_idx])[0,1]\n",
    "    \n",
    "    test_roc_auc.append(roc_auc_test_boot)\n",
    "    test_f1.append(f1_test_boot)\n",
    "    test_ftwos.append(f2_test_boot)\n",
    "    test_brier.append(brier_test_boot)\n",
    "    test_false_neg.append(false_neg_test_boot/len(idx)*100)\n",
    "    test_false_pos.append(false_pos_test_boot/len(idx)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance\n",
      "\n",
      "ROC AUC:         0.89;   95% CI 0.86-0.92\n",
      "F1:              0.45;   95% CI 0.34-0.55\n",
      "F2:              0.55;   95% CI 0.44-0.67\n",
      "Brier loss:      0.13;   95% CI 0.10-0.15\n",
      "False negatives: 3.06%;  95% CI 1.41-4.65\n",
      "False negatives: 10.49%; 95% CI 7.88-13.33\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification performance\\n\")\n",
    "\n",
    "bootstrap_roc_auc_test_mean = np.mean(test_roc_auc)\n",
    "ci_lower = np.percentile(test_roc_auc, 2.5)     # 2.5 percentile (alpha=0.025)\n",
    "ci_upper = np.percentile(test_roc_auc, 97.5)\n",
    "print(f\"ROC AUC:         {bootstrap_roc_auc_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f1_test_mean = np.mean(test_f1)\n",
    "ci_lower = np.percentile(test_f1, 2.5)\n",
    "ci_upper = np.percentile(test_f1, 97.5)\n",
    "print(f\"F1:              {bootstrap_f1_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_f2_test_mean = np.mean(test_ftwos)\n",
    "ci_lower = np.percentile(test_ftwos, 2.5)\n",
    "ci_upper = np.percentile(test_ftwos, 97.5)\n",
    "print(f\"F2:              {bootstrap_f2_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_brier_test_mean = np.mean(test_brier)\n",
    "ci_lower = np.percentile(test_brier, 2.5)\n",
    "ci_upper = np.percentile(test_brier, 97.5)\n",
    "print(f\"Brier loss:      {bootstrap_brier_test_mean:.2f};   95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_neg_test_mean = np.mean(test_false_neg)\n",
    "ci_lower = np.percentile(test_false_neg, 2.5)\n",
    "ci_upper = np.percentile(test_false_neg, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_neg_test_mean:.2f}%;  95% CI {ci_lower:.2f}-{ci_upper:.2f}\")\n",
    "\n",
    "bootstrap_false_pos_test_mean = np.mean(test_false_pos)\n",
    "ci_lower = np.percentile(test_false_pos, 2.5)\n",
    "ci_upper = np.percentile(test_false_pos, 97.5)\n",
    "print(f\"False negatives: {bootstrap_false_pos_test_mean:.2f}%; 95% CI {ci_lower:.2f}-{ci_upper:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "general_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
